{"model_class":"Job","id":"bbd44e69cb8906b508227afbe60b766d","history_id":"bbd44e69cb8906b5818b2d41fc14f7a1","tool_id":"toolshed.g2.bx.psu.edu/repos/goeckslab/tabular_learner/tabular_learner/0.1.4","state":"ok","exit_code":0,"create_time":"2026-02-08T00:38:26.710405","update_time":"2026-02-08T00:43:13.385453","galaxy_version":"25.1","external_id":null,"handler":null,"job_runner_name":null,"command_line":"python /cvmfs/main.galaxyproject.org/shed_tools/toolshed.g2.bx.psu.edu/repos/goeckslab/tabular_learner/01e7c5481f13/tabular_learner/pycaret_train.py --input_file '/corral4/main/objects/c/d/e/dataset_cdebcdd9-57d3-4a3f-8660-e0293a9ab3e3.dat' --target_col '22' --output_dir '.' --random_seed '42' --n-jobs ${GALAXY_SLOTS:-1} --train_size '0.7' --cross_validation --cross_validation_folds '10' --probability_threshold '0.25' --test_file '/corral4/main/objects/e/b/0/dataset_eb081a6d-7aba-4587-947a-b64a930a7e12.dat' --model_type 'classification' --best_model_metric 'Accuracy'","user_email":null,"user_id":"92401dda9a0b9e33","command_version":null,"params":{"test_data_choice":"{\"__current_case__\": 0, \"has_test_file\": \"yes\", \"test_file\": {\"values\": [{\"id\": 168332715, \"src\": \"hda\"}]}}","target_feature":"\"22\"","sample_id_selector":"{\"__current_case__\": 1, \"use_sample_id\": \"no\"}","model_selection":"{\"__current_case__\": 0, \"best_model_metric\": \"Accuracy\", \"classification_models\": null, \"model_type\": \"classification\"}","tune_model":"false","random_seed":"\"42\"","advanced_settings":"{\"__current_case__\": 0, \"cross_validation\": {\"__current_case__\": 0, \"cross_validation_folds\": \"10\", \"enable_cross_validation\": \"true\"}, \"customize_defaults\": \"true\", \"feature_selection\": false, \"fix_imbalance\": false, \"normalize\": false, \"polynomial_features\": false, \"probability_threshold\": \"0.25\", \"remove_multicollinearity\": false, \"remove_outliers\": false, \"train_size\": \"0.7\"}","chromInfo":"\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"","dbkey":"\"?\"","__input_ext":"\"input\""},"inputs":{"input_file":{"id":"f9cad7b01a47213515562d8d15c5db3d","src":"hda","uuid":"cdebcdd9-57d3-4a3f-8660-e0293a9ab3e3"},"test_data_choice|test_file":{"id":"f9cad7b01a4721353f443ce2cb15cd33","src":"hda","uuid":"eb081a6d-7aba-4587-947a-b64a930a7e12"}},"outputs":{"model":{"id":"f9cad7b01a47213541e9af7a2d86fed9","src":"hda","uuid":"27a88389-31d2-4013-a391-cc4f333d2dff"},"best_model_csv":{"id":"f9cad7b01a4721355f32b3a3a11aecd4","src":"hda","uuid":"c01fbeed-e68b-489b-8005-0b7aa4cb7903"},"comparison_result":{"id":"f9cad7b01a47213526f7e6ae60c97438","src":"hda","uuid":"56079acc-f54c-484e-971f-e47ff88d25ea"}},"copied_from_job_id":null,"output_collections":{},"tool_stdout":"                    Description             Value\n0                    Session id                42\n1                        Target          Response\n2                   Target type            Binary\n3           Original data shape        (1479, 22)\n4        Transformed data shape        (1479, 22)\n5   Transformed train set shape         (964, 22)\n6    Transformed test set shape         (515, 22)\n7              Numeric features                21\n8                    Preprocess              True\n9               Imputation type            simple\n10           Numeric imputation              mean\n11       Categorical imputation              mode\n12               Fold Generator   StratifiedKFold\n13                  Fold Number                10\n14                     CPU Jobs                 1\n15                      Use GPU             False\n16               Log Experiment             False\n17              Experiment Name  clf-default-name\n18                          USI              1979\n                                    Model  Accuracy     AUC  Recall   Prec.  \\\nlr                    Logistic Regression    0.7272  0.7073  0.2627  0.5582   \nridge                    Ridge Classifier    0.7251  0.7103  0.2485  0.5571   \nlda          Linear Discriminant Analysis    0.7230  0.7102  0.2768  0.5453   \ncatboost              CatBoost Classifier    0.7147  0.7017  0.2770  0.5228   \nrf               Random Forest Classifier    0.7136  0.6700  0.3017  0.5107   \ngbc          Gradient Boosting Classifier    0.7116  0.6742  0.2661  0.4948   \nada                  Ada Boost Classifier    0.7095  0.6817  0.2842  0.5158   \ndummy                    Dummy Classifier    0.7075  0.5000  0.0000  0.0000   \net                 Extra Trees Classifier    0.7023  0.6569  0.3053  0.4842   \nlightgbm  Light Gradient Boosting Machine    0.6929  0.6702  0.3583  0.4643   \nxgboost         Extreme Gradient Boosting    0.6898  0.6497  0.3550  0.4512   \nsvm                   SVM - Linear Kernel    0.6887  0.6939  0.2643  0.4113   \nknn                K Neighbors Classifier    0.6836  0.6133  0.2909  0.4335   \ndt               Decision Tree Classifier    0.6380  0.5852  0.4576  0.3966   \nqda       Quadratic Discriminant Analysis    0.4333  0.5720  0.6688  0.2977   \nnb                            Naive Bayes    0.3868  0.6562  0.8655  0.3061   \n\n              F1   Kappa     MCC  PR-AUC-Weighted  TT (Sec)  \nlr        0.3527  0.2129  0.2364           0.5339     0.140  \nridge     0.3361  0.2004  0.2265           0.0000     0.028  \nlda       0.3610  0.2128  0.2331           0.5346     0.029  \ncatboost  0.3490  0.1953  0.2146           0.5209     1.234  \nrf        0.3669  0.2058  0.2205           0.4813     0.245  \ngbc       0.3378  0.1829  0.1968           0.5099     0.235  \nada       0.3566  0.1936  0.2107           0.4781     0.154  \ndummy     0.0000  0.0000  0.0000           0.2925     0.023  \net        0.3648  0.1893  0.2001           0.4810     0.195  \nlightgbm  0.3954  0.1990  0.2052           0.4798     0.083  \nxgboost   0.3914  0.1916  0.1957           0.4697     0.104  \nsvm       0.2450  0.1321  0.1761           0.0000     0.032  \nknn       0.3450  0.1497  0.1552           0.3982     0.040  \ndt        0.4234  0.1623  0.1639           0.3481     0.030  \nqda       0.3735  0.0054  0.0173           0.3394     0.030  \nnb        0.4518  0.0354  0.0651           0.4664     0.027  \n                 Model  Accuracy     AUC  ...   Kappa     MCC  PR-AUC-Weighted\n0  Logistic Regression    0.6738  0.7597  ...  0.2971  0.3231            0.555\n\n[1 rows x 9 columns]\nWARNING: For shap='linear', shap interaction values can unfortunately not be calculated!\nNote: model_output='probability' is currently not supported for linear classifiers models with shap. So defaulting to model_output='logodds' If you really need probability outputs use shap='kernel' instead.\nNote: shap values for shap='linear' get calculated against X_background, but paramater X_background=None, so using X instead...\nGenerating self.shap_explainer = shap.LinearExplainer(model, X)...\nCalculating liftcurve_dfs...\nCalculating prediction probabilities...\nCalculating shap values...\n                    Description             Value\n0                    Session id               123\n1                        Target          Response\n2                   Target type            Binary\n3           Original data shape        (1479, 22)\n4        Transformed data shape        (1479, 22)\n5   Transformed train set shape        (1035, 22)\n6    Transformed test set shape         (444, 22)\n7              Numeric features                21\n8                    Preprocess              True\n9               Imputation type            simple\n10           Numeric imputation              mean\n11       Categorical imputation              mode\n12               Fold Generator   StratifiedKFold\n13                  Fold Number                10\n14                     CPU Jobs                -1\n15                      Use GPU             False\n16               Log Experiment             False\n17              Experiment Name  clf-default-name\n18                          USI              3e58\nCalculating permutation importances (if slow, try setting n_jobs parameter)...\n","tool_stderr":"INFO:__main__:Model kwargs: {'train_size': 0.7, 'normalize': None, 'feature_selection': None, 'cross_validation': True, 'cross_validation_folds': 10, 'remove_outliers': None, 'remove_multicollinearity': None, 'polynomial_features': None, 'feature_interaction': None, 'feature_ratio': None, 'fix_imbalance': None, 'tune_model': False, 'n_jobs': 1, 'probability_threshold': 0.25, 'best_model_metric': 'Accuracy', 'sample_id_column': None}\nINFO:__main__:Model kwargs 2: {'train_size': 0.7, 'cross_validation': True, 'cross_validation_folds': 10, 'tune_model': False, 'n_jobs': 1, 'probability_threshold': 0.25, 'best_model_metric': 'Accuracy'}\nINFO:base_model_trainer:Model kwargs: {'exp': None, 'input_file': '/corral4/main/objects/c/d/e/dataset_cdebcdd9-57d3-4a3f-8660-e0293a9ab3e3.dat', 'target_col': '22', 'output_dir': '.', 'task_type': 'classification', 'random_seed': 42, 'data': None, 'target': None, 'best_model': None, 'results': None, 'tuning_results': None, 'features_name': None, 'plot_feature_names': None, 'plots': {}, 'explainer_plots': {}, 'plots_explainer_html': None, 'trees': [], 'user_kwargs': {'train_size': 0.7, 'cross_validation': True, 'cross_validation_folds': 10, 'tune_model': False, 'n_jobs': 1, 'probability_threshold': 0.25, 'best_model_metric': 'Accuracy'}, 'train_size': 0.7, 'cross_validation': True, 'cross_validation_folds': 10, 'tune_model': False, 'n_jobs': 1, 'probability_threshold': 0.25, 'best_model_metric': 'Accuracy', 'plot_feature_limit': 30, '_shap_row_cap': None, 'imputed_training_data': None, '_best_model_metric_used': None, 'setup_params': {}, 'test_file': '/corral4/main/objects/e/b/0/dataset_eb081a6d-7aba-4587-947a-b64a930a7e12.dat', 'test_data': None}\nINFO:base_model_trainer:Loading data from /corral4/main/objects/c/d/e/dataset_cdebcdd9-57d3-4a3f-8660-e0293a9ab3e3.dat\nINFO:base_model_trainer:Original dataset columns: ['TMB', 'Systemic_therapy_history', 'Albumin', 'NLR', 'Age', 'CancerType1', 'CancerType2', 'CancerType3', 'CancerType4', 'CancerType5', 'CancerType6', 'CancerType7', 'CancerType8', 'CancerType9', 'CancerType10', 'CancerType11', 'CancerType12', 'CancerType13', 'CancerType14', 'CancerType15', 'CancerType16', 'Response']\nINFO:base_model_trainer:Dataset columns after processing: ['TMB', 'Systemic_therapy_history', 'Albumin', 'NLR', 'Age', 'CancerType1', 'CancerType2', 'CancerType3', 'CancerType4', 'CancerType5', 'CancerType6', 'CancerType7', 'CancerType8', 'CancerType9', 'CancerType10', 'CancerType11', 'CancerType12', 'CancerType13', 'CancerType14', 'CancerType15', 'CancerType16', 'Response']\nINFO:base_model_trainer:Loading test data from /corral4/main/objects/e/b/0/dataset_eb081a6d-7aba-4587-947a-b64a930a7e12.dat\nINFO:base_model_trainer:Feature plotting limit not needed (21 features <= limit 30).\nINFO:base_model_trainer:Initializing PyCaret\nINFO:base_model_trainer:{'target': 'Response', 'session_id': 42, 'html': True, 'log_experiment': False, 'system_log': False, 'index': False, 'test_data':       TMB  Systemic_therapy_history  ...  CancerType16  Response\n0    32.5                         1  ...             0         1\n1    19.3                         1  ...             1         1\n2    10.5                         1  ...             0         1\n3     3.5                         1  ...             1         0\n4    32.5                         0  ...             0         1\n..    ...                       ...  ...           ...       ...\n510   1.8                         1  ...             0         0\n511   2.6                         1  ...             0         0\n512   4.4                         1  ...             0         0\n513   2.6                         1  ...             0         0\n514   8.8                         0  ...             0         0\n\n[515 rows x 22 columns], 'train_size': 0.7, 'n_jobs': 1, 'fold': 10}\nINFO:base_model_trainer:Captured imputed training dataset from PyCaret (1479 rows, 21 features).\nINFO:base_model_trainer:Training and selecting the best model\nINFO:base_model_trainer:Ranking models using metric: Accuracy\nINFO:base_model_trainer:compare_models kwargs: {'cross_validation': True, 'fold': 10, 'sort': 'Accuracy'}\n\rProcessing:   0%|          | 0/69 [00:00<?, ?it/s]\rProcessing:   7%|▋         | 5/69 [00:01<00:18,  3.54it/s]\rProcessing:  10%|█         | 7/69 [00:01<00:12,  4.82it/s]\rProcessing:  13%|█▎        | 9/69 [00:01<00:12,  4.85it/s]\rProcessing:  16%|█▌        | 11/69 [00:02<00:09,  6.09it/s]\rProcessing:  19%|█▉        | 13/69 [00:02<00:08,  6.47it/s]\rProcessing:  22%|██▏       | 15/69 [00:02<00:07,  7.69it/s]\rProcessing:  25%|██▍       | 17/69 [00:02<00:07,  7.30it/s]\rProcessing:  28%|██▊       | 19/69 [00:03<00:06,  8.31it/s]\rProcessing:  30%|███       | 21/69 [00:03<00:06,  7.52it/s]\rProcessing:  33%|███▎      | 23/69 [00:03<00:05,  8.65it/s]\rProcessing:  36%|███▌      | 25/69 [00:03<00:05,  8.08it/s]\rProcessing:  39%|███▉      | 27/69 [00:03<00:04,  9.14it/s]\rProcessing:  42%|████▏     | 29/69 [00:06<00:17,  2.25it/s]\rProcessing:  45%|████▍     | 31/69 [00:06<00:12,  2.99it/s]\rProcessing:  48%|████▊     | 33/69 [00:06<00:10,  3.58it/s]\rProcessing:  51%|█████     | 35/69 [00:06<00:07,  4.60it/s]\rProcessing:  54%|█████▎    | 37/69 [00:08<00:12,  2.61it/s]\rProcessing:  57%|█████▋    | 39/69 [00:08<00:08,  3.44it/s]\rProcessing:  59%|█████▉    | 41/69 [00:11<00:15,  1.80it/s]\rProcessing:  62%|██████▏   | 43/69 [00:11<00:10,  2.43it/s]\rProcessing:  65%|██████▌   | 45/69 [00:11<00:07,  3.01it/s]\rProcessing:  68%|██████▊   | 47/69 [00:11<00:05,  3.92it/s]\rProcessing:  71%|███████   | 49/69 [00:13<00:09,  2.12it/s]\rProcessing:  74%|███████▍  | 51/69 [00:13<00:06,  2.82it/s]\rProcessing:  77%|███████▋  | 53/69 [00:14<00:06,  2.47it/s]\rProcessing:  80%|███████▉  | 55/69 [00:14<00:04,  3.27it/s]\rProcessing:  83%|████████▎ | 57/69 [00:15<00:04,  2.95it/s]\rProcessing:  86%|████████▌ | 59/69 [00:15<00:02,  3.85it/s]\rProcessing:  88%|████████▊ | 61/69 [00:28<00:16,  2.03s/it]\rProcessing:  91%|█████████▏| 63/69 [00:28<00:08,  1.45s/it]\rProcessing:  94%|█████████▍| 65/69 [00:28<00:04,  1.05s/it]\rProcessing:  97%|█████████▋| 67/69 [00:28<00:01,  1.32it/s]\rProcessing: 100%|██████████| 69/69 [00:29<00:00,  1.74it/s]\r                                                           \rINFO:pycaret_classification:Generating and saving plots\nINFO:pycaret_classification:Generating explainer plots\nINFO:base_model_trainer:Generating tree plots\nWARNING:base_model_trainer:Tree plots not supported for this model type.\nINFO:base_model_trainer:Saving HTML report\nINFO:base_model_trainer:Best model determined as: Logistic Regression\nINFO:feature_importance:Using provided experiment object\nINFO:feature_importance:Initializing PyCaret\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans,\n..\nalue=$const16.0)\nDEBUG:numba.core.ssa:on stmt: return $18return_value.1\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 20\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: src_index = const(int, 0)\nDEBUG:numba.core.ssa:on stmt: dest_index = dest_ndim - src_ndim\nDEBUG:numba.core.ssa:first assign: dest_index\nDEBUG:numba.core.ssa:replaced with: dest_index = dest_ndim - src_ndim\nDEBUG:numba.core.ssa:on stmt: $38compare_op.6 = src_index < src_ndim\nDEBUG:numba.core.ssa:on stmt: bool44 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $44pred = call bool44($38compare_op.6, func=bool44, args=(Var($38compare_op.6, npyimpl.py:354),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $44pred, 46, 182\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 46\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: src_index.2 = phi(incoming_values=[Var(src_index, npyimpl.py:352), Var(src_index.1, npyimpl.py:368)], incoming_blocks=[20, 150])\nDEBUG:numba.core.ssa:on stmt: src_dim_size = getitem(value=src_shape, index=src_index.2, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:on stmt: dest_dim_size = getitem(value=dest_shape, index=dest_index, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:on stmt: $const80.7 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $82compare_op.8 = dest_dim_size != $const80.7\nDEBUG:numba.core.ssa:on stmt: bool88 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $88pred = call bool88($82compare_op.8, func=bool88, args=(Var($82compare_op.8, npyimpl.py:359),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $88pred, 90, 128\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 90\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $94compare_op.2 = src_dim_size != dest_dim_size\nDEBUG:numba.core.ssa:on stmt: bool100 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, npyimpl.py:363),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $100pred, 102, 126\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 102\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $const104.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $106compare_op.2 = src_dim_size != $const104.1\nDEBUG:numba.core.ssa:on stmt: bool112 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $112pred = call bool112($106compare_op.2, func=bool112, args=(Var($106compare_op.2, npyimpl.py:363),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $112pred, 114, 126\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 114\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $const116.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_add118.2 = dest_index + $const116.1\nDEBUG:numba.core.ssa:on stmt: $122unary_negative.3 = unary(fn=<built-in function neg>, value=$binop_add118.2)\nDEBUG:numba.core.ssa:on stmt: $124return_value.4 = cast(value=$122unary_negative.3)\nDEBUG:numba.core.ssa:on stmt: return $124return_value.4\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 126\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: jump 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 128\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $const130.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $132compare_op.2 = src_dim_size != $const130.1\nDEBUG:numba.core.ssa:on stmt: bool138 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $138pred = call bool138($132compare_op.2, func=bool138, args=(Var($132compare_op.2, npyimpl.py:365),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $138pred, 140, 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 140\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: dest_shape[dest_index] = src_dim_size\nDEBUG:numba.core.ssa:on stmt: jump 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 150\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $const152.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_iadd154.2 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=src_index.2, rhs=$const152.1, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:on stmt: src_index.1 = $binop_iadd154.2\nDEBUG:numba.core.ssa:on stmt: $const162.4 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_iadd164.5 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=dest_index, rhs=$const162.4, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:on stmt: dest_index = $binop_iadd164.5\nDEBUG:numba.core.ssa:replaced with: dest_index.1 = $binop_iadd164.5\nDEBUG:numba.core.ssa:on stmt: $174compare_op.8 = src_index.1 < src_ndim\nDEBUG:numba.core.ssa:on stmt: bool180 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $180pred = call bool180($174compare_op.8, func=bool180, args=(Var($174compare_op.8, npyimpl.py:354),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $180pred, 46, 182\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 182\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $184return_value.1 = cast(value=dest_index)\nDEBUG:numba.core.ssa:on stmt: return $184return_value.1\nDEBUG:numba.core.ssa:Replaced assignments: defaultdict(<class 'list'>,\n            {20: [<numba.core.ir.Assign object at 0x14c689568350>],\n             150: [<numba.core.ir.Assign object at 0x14c689577990>]})\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 0\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: src_ndim = arg(0, name=src_ndim)\nDEBUG:numba.core.ssa:on stmt: src_shape = arg(1, name=src_shape)\nDEBUG:numba.core.ssa:on stmt: dest_ndim = arg(2, name=dest_ndim)\nDEBUG:numba.core.ssa:on stmt: dest_shape = arg(3, name=dest_shape)\nDEBUG:numba.core.ssa:on stmt: $8compare_op.2 = src_ndim > dest_ndim\nDEBUG:numba.core.ssa:on stmt: bool14 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $14pred = call bool14($8compare_op.2, func=bool14, args=(Var($8compare_op.2, npyimpl.py:347),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $14pred, 16, 20\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 16\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $const16.0 = const(int, 0)\nDEBUG:numba.core.ssa:on stmt: $18return_value.1 = cast(value=$const16.0)\nDEBUG:numba.core.ssa:on stmt: return $18return_value.1\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 20\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: src_index = const(int, 0)\nDEBUG:numba.core.ssa:on stmt: dest_index = dest_ndim - src_ndim\nDEBUG:numba.core.ssa:on stmt: $38compare_op.6 = src_index < src_ndim\nDEBUG:numba.core.ssa:on stmt: bool44 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $44pred = call bool44($38compare_op.6, func=bool44, args=(Var($38compare_op.6, npyimpl.py:354),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $44pred, 46, 182\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 46\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: src_index.2 = phi(incoming_values=[Var(src_index, npyimpl.py:352), Var(src_index.1, npyimpl.py:368)], incoming_blocks=[20, 150])\nDEBUG:numba.core.ssa:on stmt: src_dim_size = getitem(value=src_shape, index=src_index.2, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:on stmt: dest_dim_size = getitem(value=dest_shape, index=dest_index, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:find_def var='dest_index' stmt=dest_dim_size = getitem(value=dest_shape, index=dest_index, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:find_def_from_top label 46\nDEBUG:numba.core.ssa:insert phi node dest_index.2 = phi(incoming_values=[], incoming_blocks=[]) at 46\nDEBUG:numba.core.ssa:find_def_from_bottom label 20\nDEBUG:numba.core.ssa:incoming_def dest_index = dest_ndim - src_ndim\nDEBUG:numba.core.ssa:find_def_from_bottom label 150\nDEBUG:numba.core.ssa:incoming_def dest_index.1 = $binop_iadd164.5\nDEBUG:numba.core.ssa:replaced with: dest_dim_size = getitem(value=dest_shape, index=dest_index.2, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:on stmt: $const80.7 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $82compare_op.8 = dest_dim_size != $const80.7\nDEBUG:numba.core.ssa:on stmt: bool88 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $88pred = call bool88($82compare_op.8, func=bool88, args=(Var($82compare_op.8, npyimpl.py:359),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $88pred, 90, 128\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 90\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $94compare_op.2 = src_dim_size != dest_dim_size\nDEBUG:numba.core.ssa:on stmt: bool100 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, npyimpl.py:363),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $100pred, 102, 126\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 102\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $const104.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $106compare_op.2 = src_dim_size != $const104.1\nDEBUG:numba.core.ssa:on stmt: bool112 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $112pred = call bool112($106compare_op.2, func=bool112, args=(Var($106compare_op.2, npyimpl.py:363),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $112pred, 114, 126\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 114\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $const116.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_add118.2 = dest_index + $const116.1\nDEBUG:numba.core.ssa:find_def var='dest_index' stmt=$binop_add118.2 = dest_index + $const116.1\nDEBUG:numba.core.ssa:find_def_from_top label 114\nDEBUG:numba.core.ssa:idom 102 from label 114\nDEBUG:numba.core.ssa:find_def_from_bottom label 102\nDEBUG:numba.core.ssa:find_def_from_top label 102\nDEBUG:numba.core.ssa:idom 90 from label 102\nDEBUG:numba.core.ssa:find_def_from_bottom label 90\nDEBUG:numba.core.ssa:find_def_from_top label 90\nDEBUG:numba.core.ssa:idom 46 from label 90\nDEBUG:numba.core.ssa:find_def_from_bottom label 46\nDEBUG:numba.core.ssa:replaced with: $binop_add118.2 = dest_index.2 + $const116.1\nDEBUG:numba.core.ssa:on stmt: $122unary_negative.3 = unary(fn=<built-in function neg>, value=$binop_add118.2)\nDEBUG:numba.core.ssa:on stmt: $124return_value.4 = cast(value=$122unary_negative.3)\nDEBUG:numba.core.ssa:on stmt: return $124return_value.4\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 126\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: jump 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 128\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $const130.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $132compare_op.2 = src_dim_size != $const130.1\nDEBUG:numba.core.ssa:on stmt: bool138 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $138pred = call bool138($132compare_op.2, func=bool138, args=(Var($132compare_op.2, npyimpl.py:365),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $138pred, 140, 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 140\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: dest_shape[dest_index] = src_dim_size\nDEBUG:numba.core.ssa:find_def var='dest_index' stmt=dest_shape[dest_index] = src_dim_size\nDEBUG:numba.core.ssa:find_def_from_top label 140\nDEBUG:numba.core.ssa:idom 128 from label 140\nDEBUG:numba.core.ssa:find_def_from_bottom label 128\nDEBUG:numba.core.ssa:find_def_from_top label 128\nDEBUG:numba.core.ssa:idom 46 from label 128\nDEBUG:numba.core.ssa:find_def_from_bottom label 46\nDEBUG:numba.core.ssa:replaced with: dest_shape[dest_index.2] = src_dim_size\nDEBUG:numba.core.ssa:on stmt: jump 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 150\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $const152.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_iadd154.2 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=src_index.2, rhs=$const152.1, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:on stmt: src_index.1 = $binop_iadd154.2\nDEBUG:numba.core.ssa:on stmt: $const162.4 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_iadd164.5 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=dest_index, rhs=$const162.4, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:find_def var='dest_index' stmt=$binop_iadd164.5 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=dest_index, rhs=$const162.4, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:find_def_from_top label 150\nDEBUG:numba.core.ssa:idom 46 from label 150\nDEBUG:numba.core.ssa:find_def_from_bottom label 46\nDEBUG:numba.core.ssa:replaced with: $binop_iadd164.5 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=dest_index.2, rhs=$const162.4, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:on stmt: dest_index.1 = $binop_iadd164.5\nDEBUG:numba.core.ssa:on stmt: $174compare_op.8 = src_index.1 < src_ndim\nDEBUG:numba.core.ssa:on stmt: bool180 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $180pred = call bool180($174compare_op.8, func=bool180, args=(Var($174compare_op.8, npyimpl.py:354),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $180pred, 46, 182\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 182\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $184return_value.1 = cast(value=dest_index)\nDEBUG:numba.core.ssa:find_def var='dest_index' stmt=$184return_value.1 = cast(value=dest_index)\nDEBUG:numba.core.ssa:find_def_from_top label 182\nDEBUG:numba.core.ssa:insert phi node dest_index.3 = phi(incoming_values=[], incoming_blocks=[]) at 182\nDEBUG:numba.core.ssa:find_def_from_bottom label 20\nDEBUG:numba.core.ssa:incoming_def dest_index = dest_ndim - src_ndim\nDEBUG:numba.core.ssa:find_def_from_bottom label 150\nDEBUG:numba.core.ssa:incoming_def dest_index.1 = $binop_iadd164.5\nDEBUG:numba.core.ssa:replaced with: $184return_value.1 = cast(value=dest_index.3)\nDEBUG:numba.core.ssa:on stmt: return $184return_value.1\nWARNING:feature_importance:SHAP computation failed due to feature-name mismatch (The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n). Falling back to model-agnostic SHAP explainer.\nERROR:feature_importance:Model-agnostic SHAP fallback also failed: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n\nINFO:feature_importance:Generating HTML report\nINFO:base_model_trainer:HTML report generated at: ./comparison_result.html\n","job_stdout":"","job_stderr":"","stdout":"                    Description             Value\n0                    Session id                42\n1                        Target          Response\n2                   Target type            Binary\n3           Original data shape        (1479, 22)\n4        Transformed data shape        (1479, 22)\n5   Transformed train set shape         (964, 22)\n6    Transformed test set shape         (515, 22)\n7              Numeric features                21\n8                    Preprocess              True\n9               Imputation type            simple\n10           Numeric imputation              mean\n11       Categorical imputation              mode\n12               Fold Generator   StratifiedKFold\n13                  Fold Number                10\n14                     CPU Jobs                 1\n15                      Use GPU             False\n16               Log Experiment             False\n17              Experiment Name  clf-default-name\n18                          USI              1979\n                                    Model  Accuracy     AUC  Recall   Prec.  \\\nlr                    Logistic Regression    0.7272  0.7073  0.2627  0.5582   \nridge                    Ridge Classifier    0.7251  0.7103  0.2485  0.5571   \nlda          Linear Discriminant Analysis    0.7230  0.7102  0.2768  0.5453   \ncatboost              CatBoost Classifier    0.7147  0.7017  0.2770  0.5228   \nrf               Random Forest Classifier    0.7136  0.6700  0.3017  0.5107   \ngbc          Gradient Boosting Classifier    0.7116  0.6742  0.2661  0.4948   \nada                  Ada Boost Classifier    0.7095  0.6817  0.2842  0.5158   \ndummy                    Dummy Classifier    0.7075  0.5000  0.0000  0.0000   \net                 Extra Trees Classifier    0.7023  0.6569  0.3053  0.4842   \nlightgbm  Light Gradient Boosting Machine    0.6929  0.6702  0.3583  0.4643   \nxgboost         Extreme Gradient Boosting    0.6898  0.6497  0.3550  0.4512   \nsvm                   SVM - Linear Kernel    0.6887  0.6939  0.2643  0.4113   \nknn                K Neighbors Classifier    0.6836  0.6133  0.2909  0.4335   \ndt               Decision Tree Classifier    0.6380  0.5852  0.4576  0.3966   \nqda       Quadratic Discriminant Analysis    0.4333  0.5720  0.6688  0.2977   \nnb                            Naive Bayes    0.3868  0.6562  0.8655  0.3061   \n\n              F1   Kappa     MCC  PR-AUC-Weighted  TT (Sec)  \nlr        0.3527  0.2129  0.2364           0.5339     0.140  \nridge     0.3361  0.2004  0.2265           0.0000     0.028  \nlda       0.3610  0.2128  0.2331           0.5346     0.029  \ncatboost  0.3490  0.1953  0.2146           0.5209     1.234  \nrf        0.3669  0.2058  0.2205           0.4813     0.245  \ngbc       0.3378  0.1829  0.1968           0.5099     0.235  \nada       0.3566  0.1936  0.2107           0.4781     0.154  \ndummy     0.0000  0.0000  0.0000           0.2925     0.023  \net        0.3648  0.1893  0.2001           0.4810     0.195  \nlightgbm  0.3954  0.1990  0.2052           0.4798     0.083  \nxgboost   0.3914  0.1916  0.1957           0.4697     0.104  \nsvm       0.2450  0.1321  0.1761           0.0000     0.032  \nknn       0.3450  0.1497  0.1552           0.3982     0.040  \ndt        0.4234  0.1623  0.1639           0.3481     0.030  \nqda       0.3735  0.0054  0.0173           0.3394     0.030  \nnb        0.4518  0.0354  0.0651           0.4664     0.027  \n                 Model  Accuracy     AUC  ...   Kappa     MCC  PR-AUC-Weighted\n0  Logistic Regression    0.6738  0.7597  ...  0.2971  0.3231            0.555\n\n[1 rows x 9 columns]\nWARNING: For shap='linear', shap interaction values can unfortunately not be calculated!\nNote: model_output='probability' is currently not supported for linear classifiers models with shap. So defaulting to model_output='logodds' If you really need probability outputs use shap='kernel' instead.\nNote: shap values for shap='linear' get calculated against X_background, but paramater X_background=None, so using X instead...\nGenerating self.shap_explainer = shap.LinearExplainer(model, X)...\nCalculating liftcurve_dfs...\nCalculating prediction probabilities...\nCalculating shap values...\n                    Description             Value\n0                    Session id               123\n1                        Target          Response\n2                   Target type            Binary\n3           Original data shape        (1479, 22)\n4        Transformed data shape        (1479, 22)\n5   Transformed train set shape        (1035, 22)\n6    Transformed test set shape         (444, 22)\n7              Numeric features                21\n8                    Preprocess              True\n9               Imputation type            simple\n10           Numeric imputation              mean\n11       Categorical imputation              mode\n12               Fold Generator   StratifiedKFold\n13                  Fold Number                10\n14                     CPU Jobs                -1\n15                      Use GPU             False\n16               Log Experiment             False\n17              Experiment Name  clf-default-name\n18                          USI              3e58\nCalculating permutation importances (if slow, try setting n_jobs parameter)...\n","stderr":"INFO:__main__:Model kwargs: {'train_size': 0.7, 'normalize': None, 'feature_selection': None, 'cross_validation': True, 'cross_validation_folds': 10, 'remove_outliers': None, 'remove_multicollinearity': None, 'polynomial_features': None, 'feature_interaction': None, 'feature_ratio': None, 'fix_imbalance': None, 'tune_model': False, 'n_jobs': 1, 'probability_threshold': 0.25, 'best_model_metric': 'Accuracy', 'sample_id_column': None}\nINFO:__main__:Model kwargs 2: {'train_size': 0.7, 'cross_validation': True, 'cross_validation_folds': 10, 'tune_model': False, 'n_jobs': 1, 'probability_threshold': 0.25, 'best_model_metric': 'Accuracy'}\nINFO:base_model_trainer:Model kwargs: {'exp': None, 'input_file': '/corral4/main/objects/c/d/e/dataset_cdebcdd9-57d3-4a3f-8660-e0293a9ab3e3.dat', 'target_col': '22', 'output_dir': '.', 'task_type': 'classification', 'random_seed': 42, 'data': None, 'target': None, 'best_model': None, 'results': None, 'tuning_results': None, 'features_name': None, 'plot_feature_names': None, 'plots': {}, 'explainer_plots': {}, 'plots_explainer_html': None, 'trees': [], 'user_kwargs': {'train_size': 0.7, 'cross_validation': True, 'cross_validation_folds': 10, 'tune_model': False, 'n_jobs': 1, 'probability_threshold': 0.25, 'best_model_metric': 'Accuracy'}, 'train_size': 0.7, 'cross_validation': True, 'cross_validation_folds': 10, 'tune_model': False, 'n_jobs': 1, 'probability_threshold': 0.25, 'best_model_metric': 'Accuracy', 'plot_feature_limit': 30, '_shap_row_cap': None, 'imputed_training_data': None, '_best_model_metric_used': None, 'setup_params': {}, 'test_file': '/corral4/main/objects/e/b/0/dataset_eb081a6d-7aba-4587-947a-b64a930a7e12.dat', 'test_data': None}\nINFO:base_model_trainer:Loading data from /corral4/main/objects/c/d/e/dataset_cdebcdd9-57d3-4a3f-8660-e0293a9ab3e3.dat\nINFO:base_model_trainer:Original dataset columns: ['TMB', 'Systemic_therapy_history', 'Albumin', 'NLR', 'Age', 'CancerType1', 'CancerType2', 'CancerType3', 'CancerType4', 'CancerType5', 'CancerType6', 'CancerType7', 'CancerType8', 'CancerType9', 'CancerType10', 'CancerType11', 'CancerType12', 'CancerType13', 'CancerType14', 'CancerType15', 'CancerType16', 'Response']\nINFO:base_model_trainer:Dataset columns after processing: ['TMB', 'Systemic_therapy_history', 'Albumin', 'NLR', 'Age', 'CancerType1', 'CancerType2', 'CancerType3', 'CancerType4', 'CancerType5', 'CancerType6', 'CancerType7', 'CancerType8', 'CancerType9', 'CancerType10', 'CancerType11', 'CancerType12', 'CancerType13', 'CancerType14', 'CancerType15', 'CancerType16', 'Response']\nINFO:base_model_trainer:Loading test data from /corral4/main/objects/e/b/0/dataset_eb081a6d-7aba-4587-947a-b64a930a7e12.dat\nINFO:base_model_trainer:Feature plotting limit not needed (21 features <= limit 30).\nINFO:base_model_trainer:Initializing PyCaret\nINFO:base_model_trainer:{'target': 'Response', 'session_id': 42, 'html': True, 'log_experiment': False, 'system_log': False, 'index': False, 'test_data':       TMB  Systemic_therapy_history  ...  CancerType16  Response\n0    32.5                         1  ...             0         1\n1    19.3                         1  ...             1         1\n2    10.5                         1  ...             0         1\n3     3.5                         1  ...             1         0\n4    32.5                         0  ...             0         1\n..    ...                       ...  ...           ...       ...\n510   1.8                         1  ...             0         0\n511   2.6                         1  ...             0         0\n512   4.4                         1  ...             0         0\n513   2.6                         1  ...             0         0\n514   8.8                         0  ...             0         0\n\n[515 rows x 22 columns], 'train_size': 0.7, 'n_jobs': 1, 'fold': 10}\nINFO:base_model_trainer:Captured imputed training dataset from PyCaret (1479 rows, 21 features).\nINFO:base_model_trainer:Training and selecting the best model\nINFO:base_model_trainer:Ranking models using metric: Accuracy\nINFO:base_model_trainer:compare_models kwargs: {'cross_validation': True, 'fold': 10, 'sort': 'Accuracy'}\n\rProcessing:   0%|          | 0/69 [00:00<?, ?it/s]\rProcessing:   7%|▋         | 5/69 [00:01<00:18,  3.54it/s]\rProcessing:  10%|█         | 7/69 [00:01<00:12,  4.82it/s]\rProcessing:  13%|█▎        | 9/69 [00:01<00:12,  4.85it/s]\rProcessing:  16%|█▌        | 11/69 [00:02<00:09,  6.09it/s]\rProcessing:  19%|█▉        | 13/69 [00:02<00:08,  6.47it/s]\rProcessing:  22%|██▏       | 15/69 [00:02<00:07,  7.69it/s]\rProcessing:  25%|██▍       | 17/69 [00:02<00:07,  7.30it/s]\rProcessing:  28%|██▊       | 19/69 [00:03<00:06,  8.31it/s]\rProcessing:  30%|███       | 21/69 [00:03<00:06,  7.52it/s]\rProcessing:  33%|███▎      | 23/69 [00:03<00:05,  8.65it/s]\rProcessing:  36%|███▌      | 25/69 [00:03<00:05,  8.08it/s]\rProcessing:  39%|███▉      | 27/69 [00:03<00:04,  9.14it/s]\rProcessing:  42%|████▏     | 29/69 [00:06<00:17,  2.25it/s]\rProcessing:  45%|████▍     | 31/69 [00:06<00:12,  2.99it/s]\rProcessing:  48%|████▊     | 33/69 [00:06<00:10,  3.58it/s]\rProcessing:  51%|█████     | 35/69 [00:06<00:07,  4.60it/s]\rProcessing:  54%|█████▎    | 37/69 [00:08<00:12,  2.61it/s]\rProcessing:  57%|█████▋    | 39/69 [00:08<00:08,  3.44it/s]\rProcessing:  59%|█████▉    | 41/69 [00:11<00:15,  1.80it/s]\rProcessing:  62%|██████▏   | 43/69 [00:11<00:10,  2.43it/s]\rProcessing:  65%|██████▌   | 45/69 [00:11<00:07,  3.01it/s]\rProcessing:  68%|██████▊   | 47/69 [00:11<00:05,  3.92it/s]\rProcessing:  71%|███████   | 49/69 [00:13<00:09,  2.12it/s]\rProcessing:  74%|███████▍  | 51/69 [00:13<00:06,  2.82it/s]\rProcessing:  77%|███████▋  | 53/69 [00:14<00:06,  2.47it/s]\rProcessing:  80%|███████▉  | 55/69 [00:14<00:04,  3.27it/s]\rProcessing:  83%|████████▎ | 57/69 [00:15<00:04,  2.95it/s]\rProcessing:  86%|████████▌ | 59/69 [00:15<00:02,  3.85it/s]\rProcessing:  88%|████████▊ | 61/69 [00:28<00:16,  2.03s/it]\rProcessing:  91%|█████████▏| 63/69 [00:28<00:08,  1.45s/it]\rProcessing:  94%|█████████▍| 65/69 [00:28<00:04,  1.05s/it]\rProcessing:  97%|█████████▋| 67/69 [00:28<00:01,  1.32it/s]\rProcessing: 100%|██████████| 69/69 [00:29<00:00,  1.74it/s]\r                                                           \rINFO:pycaret_classification:Generating and saving plots\nINFO:pycaret_classification:Generating explainer plots\nINFO:base_model_trainer:Generating tree plots\nWARNING:base_model_trainer:Tree plots not supported for this model type.\nINFO:base_model_trainer:Saving HTML report\nINFO:base_model_trainer:Best model determined as: Logistic Regression\nINFO:feature_importance:Using provided experiment object\nINFO:feature_importance:Initializing PyCaret\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\nWARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans,\n..\nalue=$const16.0)\nDEBUG:numba.core.ssa:on stmt: return $18return_value.1\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 20\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: src_index = const(int, 0)\nDEBUG:numba.core.ssa:on stmt: dest_index = dest_ndim - src_ndim\nDEBUG:numba.core.ssa:first assign: dest_index\nDEBUG:numba.core.ssa:replaced with: dest_index = dest_ndim - src_ndim\nDEBUG:numba.core.ssa:on stmt: $38compare_op.6 = src_index < src_ndim\nDEBUG:numba.core.ssa:on stmt: bool44 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $44pred = call bool44($38compare_op.6, func=bool44, args=(Var($38compare_op.6, npyimpl.py:354),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $44pred, 46, 182\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 46\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: src_index.2 = phi(incoming_values=[Var(src_index, npyimpl.py:352), Var(src_index.1, npyimpl.py:368)], incoming_blocks=[20, 150])\nDEBUG:numba.core.ssa:on stmt: src_dim_size = getitem(value=src_shape, index=src_index.2, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:on stmt: dest_dim_size = getitem(value=dest_shape, index=dest_index, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:on stmt: $const80.7 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $82compare_op.8 = dest_dim_size != $const80.7\nDEBUG:numba.core.ssa:on stmt: bool88 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $88pred = call bool88($82compare_op.8, func=bool88, args=(Var($82compare_op.8, npyimpl.py:359),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $88pred, 90, 128\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 90\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $94compare_op.2 = src_dim_size != dest_dim_size\nDEBUG:numba.core.ssa:on stmt: bool100 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, npyimpl.py:363),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $100pred, 102, 126\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 102\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $const104.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $106compare_op.2 = src_dim_size != $const104.1\nDEBUG:numba.core.ssa:on stmt: bool112 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $112pred = call bool112($106compare_op.2, func=bool112, args=(Var($106compare_op.2, npyimpl.py:363),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $112pred, 114, 126\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 114\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $const116.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_add118.2 = dest_index + $const116.1\nDEBUG:numba.core.ssa:on stmt: $122unary_negative.3 = unary(fn=<built-in function neg>, value=$binop_add118.2)\nDEBUG:numba.core.ssa:on stmt: $124return_value.4 = cast(value=$122unary_negative.3)\nDEBUG:numba.core.ssa:on stmt: return $124return_value.4\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 126\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: jump 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 128\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $const130.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $132compare_op.2 = src_dim_size != $const130.1\nDEBUG:numba.core.ssa:on stmt: bool138 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $138pred = call bool138($132compare_op.2, func=bool138, args=(Var($132compare_op.2, npyimpl.py:365),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $138pred, 140, 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 140\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: dest_shape[dest_index] = src_dim_size\nDEBUG:numba.core.ssa:on stmt: jump 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 150\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $const152.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_iadd154.2 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=src_index.2, rhs=$const152.1, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:on stmt: src_index.1 = $binop_iadd154.2\nDEBUG:numba.core.ssa:on stmt: $const162.4 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_iadd164.5 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=dest_index, rhs=$const162.4, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:on stmt: dest_index = $binop_iadd164.5\nDEBUG:numba.core.ssa:replaced with: dest_index.1 = $binop_iadd164.5\nDEBUG:numba.core.ssa:on stmt: $174compare_op.8 = src_index.1 < src_ndim\nDEBUG:numba.core.ssa:on stmt: bool180 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $180pred = call bool180($174compare_op.8, func=bool180, args=(Var($174compare_op.8, npyimpl.py:354),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $180pred, 46, 182\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 182\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FreshVarHandler object at 0x14c689569450>\nDEBUG:numba.core.ssa:on stmt: $184return_value.1 = cast(value=dest_index)\nDEBUG:numba.core.ssa:on stmt: return $184return_value.1\nDEBUG:numba.core.ssa:Replaced assignments: defaultdict(<class 'list'>,\n            {20: [<numba.core.ir.Assign object at 0x14c689568350>],\n             150: [<numba.core.ir.Assign object at 0x14c689577990>]})\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 0\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: src_ndim = arg(0, name=src_ndim)\nDEBUG:numba.core.ssa:on stmt: src_shape = arg(1, name=src_shape)\nDEBUG:numba.core.ssa:on stmt: dest_ndim = arg(2, name=dest_ndim)\nDEBUG:numba.core.ssa:on stmt: dest_shape = arg(3, name=dest_shape)\nDEBUG:numba.core.ssa:on stmt: $8compare_op.2 = src_ndim > dest_ndim\nDEBUG:numba.core.ssa:on stmt: bool14 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $14pred = call bool14($8compare_op.2, func=bool14, args=(Var($8compare_op.2, npyimpl.py:347),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $14pred, 16, 20\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 16\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $const16.0 = const(int, 0)\nDEBUG:numba.core.ssa:on stmt: $18return_value.1 = cast(value=$const16.0)\nDEBUG:numba.core.ssa:on stmt: return $18return_value.1\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 20\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: src_index = const(int, 0)\nDEBUG:numba.core.ssa:on stmt: dest_index = dest_ndim - src_ndim\nDEBUG:numba.core.ssa:on stmt: $38compare_op.6 = src_index < src_ndim\nDEBUG:numba.core.ssa:on stmt: bool44 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $44pred = call bool44($38compare_op.6, func=bool44, args=(Var($38compare_op.6, npyimpl.py:354),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $44pred, 46, 182\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 46\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: src_index.2 = phi(incoming_values=[Var(src_index, npyimpl.py:352), Var(src_index.1, npyimpl.py:368)], incoming_blocks=[20, 150])\nDEBUG:numba.core.ssa:on stmt: src_dim_size = getitem(value=src_shape, index=src_index.2, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:on stmt: dest_dim_size = getitem(value=dest_shape, index=dest_index, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:find_def var='dest_index' stmt=dest_dim_size = getitem(value=dest_shape, index=dest_index, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:find_def_from_top label 46\nDEBUG:numba.core.ssa:insert phi node dest_index.2 = phi(incoming_values=[], incoming_blocks=[]) at 46\nDEBUG:numba.core.ssa:find_def_from_bottom label 20\nDEBUG:numba.core.ssa:incoming_def dest_index = dest_ndim - src_ndim\nDEBUG:numba.core.ssa:find_def_from_bottom label 150\nDEBUG:numba.core.ssa:incoming_def dest_index.1 = $binop_iadd164.5\nDEBUG:numba.core.ssa:replaced with: dest_dim_size = getitem(value=dest_shape, index=dest_index.2, fn=<built-in function getitem>)\nDEBUG:numba.core.ssa:on stmt: $const80.7 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $82compare_op.8 = dest_dim_size != $const80.7\nDEBUG:numba.core.ssa:on stmt: bool88 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $88pred = call bool88($82compare_op.8, func=bool88, args=(Var($82compare_op.8, npyimpl.py:359),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $88pred, 90, 128\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 90\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $94compare_op.2 = src_dim_size != dest_dim_size\nDEBUG:numba.core.ssa:on stmt: bool100 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $100pred = call bool100($94compare_op.2, func=bool100, args=(Var($94compare_op.2, npyimpl.py:363),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $100pred, 102, 126\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 102\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $const104.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $106compare_op.2 = src_dim_size != $const104.1\nDEBUG:numba.core.ssa:on stmt: bool112 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $112pred = call bool112($106compare_op.2, func=bool112, args=(Var($106compare_op.2, npyimpl.py:363),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $112pred, 114, 126\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 114\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $const116.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_add118.2 = dest_index + $const116.1\nDEBUG:numba.core.ssa:find_def var='dest_index' stmt=$binop_add118.2 = dest_index + $const116.1\nDEBUG:numba.core.ssa:find_def_from_top label 114\nDEBUG:numba.core.ssa:idom 102 from label 114\nDEBUG:numba.core.ssa:find_def_from_bottom label 102\nDEBUG:numba.core.ssa:find_def_from_top label 102\nDEBUG:numba.core.ssa:idom 90 from label 102\nDEBUG:numba.core.ssa:find_def_from_bottom label 90\nDEBUG:numba.core.ssa:find_def_from_top label 90\nDEBUG:numba.core.ssa:idom 46 from label 90\nDEBUG:numba.core.ssa:find_def_from_bottom label 46\nDEBUG:numba.core.ssa:replaced with: $binop_add118.2 = dest_index.2 + $const116.1\nDEBUG:numba.core.ssa:on stmt: $122unary_negative.3 = unary(fn=<built-in function neg>, value=$binop_add118.2)\nDEBUG:numba.core.ssa:on stmt: $124return_value.4 = cast(value=$122unary_negative.3)\nDEBUG:numba.core.ssa:on stmt: return $124return_value.4\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 126\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: jump 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 128\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $const130.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $132compare_op.2 = src_dim_size != $const130.1\nDEBUG:numba.core.ssa:on stmt: bool138 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $138pred = call bool138($132compare_op.2, func=bool138, args=(Var($132compare_op.2, npyimpl.py:365),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $138pred, 140, 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 140\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: dest_shape[dest_index] = src_dim_size\nDEBUG:numba.core.ssa:find_def var='dest_index' stmt=dest_shape[dest_index] = src_dim_size\nDEBUG:numba.core.ssa:find_def_from_top label 140\nDEBUG:numba.core.ssa:idom 128 from label 140\nDEBUG:numba.core.ssa:find_def_from_bottom label 128\nDEBUG:numba.core.ssa:find_def_from_top label 128\nDEBUG:numba.core.ssa:idom 46 from label 128\nDEBUG:numba.core.ssa:find_def_from_bottom label 46\nDEBUG:numba.core.ssa:replaced with: dest_shape[dest_index.2] = src_dim_size\nDEBUG:numba.core.ssa:on stmt: jump 150\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 150\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $const152.1 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_iadd154.2 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=src_index.2, rhs=$const152.1, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:on stmt: src_index.1 = $binop_iadd154.2\nDEBUG:numba.core.ssa:on stmt: $const162.4 = const(int, 1)\nDEBUG:numba.core.ssa:on stmt: $binop_iadd164.5 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=dest_index, rhs=$const162.4, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:find_def var='dest_index' stmt=$binop_iadd164.5 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=dest_index, rhs=$const162.4, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:find_def_from_top label 150\nDEBUG:numba.core.ssa:idom 46 from label 150\nDEBUG:numba.core.ssa:find_def_from_bottom label 46\nDEBUG:numba.core.ssa:replaced with: $binop_iadd164.5 = inplace_binop(fn=<built-in function iadd>, immutable_fn=<built-in function add>, lhs=dest_index.2, rhs=$const162.4, static_lhs=Undefined, static_rhs=Undefined)\nDEBUG:numba.core.ssa:on stmt: dest_index.1 = $binop_iadd164.5\nDEBUG:numba.core.ssa:on stmt: $174compare_op.8 = src_index.1 < src_ndim\nDEBUG:numba.core.ssa:on stmt: bool180 = global(bool: <class 'bool'>)\nDEBUG:numba.core.ssa:on stmt: $180pred = call bool180($174compare_op.8, func=bool180, args=(Var($174compare_op.8, npyimpl.py:354),), kws=(), vararg=None, varkwarg=None, target=None)\nDEBUG:numba.core.ssa:on stmt: branch $180pred, 46, 182\nDEBUG:numba.core.ssa:==== SSA block rewrite pass on 182\nDEBUG:numba.core.ssa:Running <numba.core.ssa._FixSSAVars object at 0x14c68956d290>\nDEBUG:numba.core.ssa:on stmt: $184return_value.1 = cast(value=dest_index)\nDEBUG:numba.core.ssa:find_def var='dest_index' stmt=$184return_value.1 = cast(value=dest_index)\nDEBUG:numba.core.ssa:find_def_from_top label 182\nDEBUG:numba.core.ssa:insert phi node dest_index.3 = phi(incoming_values=[], incoming_blocks=[]) at 182\nDEBUG:numba.core.ssa:find_def_from_bottom label 20\nDEBUG:numba.core.ssa:incoming_def dest_index = dest_ndim - src_ndim\nDEBUG:numba.core.ssa:find_def_from_bottom label 150\nDEBUG:numba.core.ssa:incoming_def dest_index.1 = $binop_iadd164.5\nDEBUG:numba.core.ssa:replaced with: $184return_value.1 = cast(value=dest_index.3)\nDEBUG:numba.core.ssa:on stmt: return $184return_value.1\nWARNING:feature_importance:SHAP computation failed due to feature-name mismatch (The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n). Falling back to model-agnostic SHAP explainer.\nERROR:feature_importance:Model-agnostic SHAP fallback also failed: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n\nINFO:feature_importance:Generating HTML report\nINFO:base_model_trainer:HTML report generated at: ./comparison_result.html\n","job_messages":[],"dependencies":[],"job_metrics":null}
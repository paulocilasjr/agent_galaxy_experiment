{"model_class":"Job","id":"bbd44e69cb8906b5349dbb08e34ca0d8","history_id":"bbd44e69cb8906b5ce223e9a81174ae0","tool_id":"toolshed.g2.bx.psu.edu/repos/goeckslab/multimodal_learner/multimodal_learner/0.1.5","state":"ok","exit_code":0,"create_time":"2026-02-09T21:33:29.553834","update_time":"2026-02-09T22:24:14.056693","galaxy_version":"25.1","external_id":null,"handler":null,"job_runner_name":null,"command_line":"set -e; ln -sf '/jetstream2/scratch/main/jobs/74514518/inputs/dataset_bed0da13-577a-4094-bb36-e678609c48ff.dat' 'train_input.csv'; ln -sf '/jetstream2/scratch/main/jobs/74514518/inputs/dataset_8afe987e-6cca-49ac-a972-45ab1376c13d.dat' 'test_input.csv';  export TORCH_HOME=\"./torch_cache\" && export HF_HOME=\"./hf_cache\" && export HUGGINGFACE_HUB_CACHE=\"./hf_cache/hub\" && mkdir -p \"./torch_cache\" \"./hf_cache/hub\" &&  python '/jetstream2/scratch/main/jobs/74514518/tool_files/multimodal_learner.py' --input_csv_train 'train_input.csv' --input_csv_test 'test_input.csv' --target_column '3' --sample_id_column '1'  --images_zip '/jetstream2/scratch/main/jobs/74514518/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat' --missing_image_strategy 'false' --backbone_image 'caformer_b36.sail_in22k_ft_in1k_384'  --backbone_text 'microsoft/deberta-v3-base'  --preset 'best_quality' --eval_metric 'roc_auc'  --random_seed '42' --time_limit 43200   --output_json '/jetstream2/scratch/main/jobs/74514518/outputs/dataset_7cb494f0-40de-48e3-ab76-ef0e39783b47.dat' --output_html '/jetstream2/scratch/main/jobs/74514518/outputs/dataset_ead64feb-db3d-4766-a053-ba4144a2543e.dat' --output_config '/jetstream2/scratch/main/jobs/74514518/outputs/dataset_091f735a-6d6a-4fbf-a9e4-dd8e05f2c9b2.dat'","user_email":null,"user_id":"92401dda9a0b9e33","command_version":"","params":{"target_column":"\"3\"","sample_id_selector":"{\"__current_case__\": 0, \"sample_id_column\": \"1\", \"use_sample_id\": \"yes\"}","test_dataset_conditional":"{\"__current_case__\": 0, \"has_test_dataset\": true, \"input_test\": {\"values\": [{\"id\": 168376039, \"src\": \"hda\"}]}}","backbone_text":"\"microsoft/deberta-v3-base\"","use_images_conditional":"{\"__current_case__\": 0, \"backbone_image\": \"caformer_b36.sail_in22k_ft_in1k_384\", \"images_zip_repeat\": [{\"__index__\": 0, \"images_zip\": {\"values\": [{\"id\": 168376040, \"src\": \"hda\"}]}}], \"missing_image_strategy\": false, \"use_images\": true}","preset":"\"best_quality\"","eval_metric":"\"roc_auc\"","random_seed":"\"42\"","time_limit":"\"43200\"","deterministic":"false","customize_defaults_conditional":"{\"__current_case__\": 1, \"customize_defaults\": false}","chromInfo":"\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"","dbkey":"\"?\"","__input_ext":"\"input\""},"inputs":{"input_csv":{"id":"f9cad7b01a472135214deb0f5acedc0b","src":"hda","uuid":"bed0da13-577a-4094-bb36-e678609c48ff"},"test_dataset_conditional|input_test":{"id":"f9cad7b01a4721356b6decc42b7e78f0","src":"hda","uuid":"8afe987e-6cca-49ac-a972-45ab1376c13d"},"use_images_conditional|images_zip_repeat_0|images_zip":{"id":"f9cad7b01a4721357c0e9f7ba4c68487","src":"hda","uuid":"666b7df2-0818-43d9-b778-cb5a83c8cdcd"}},"outputs":{"output_html":{"id":"f9cad7b01a4721355f6f864ae9ccad3e","src":"hda","uuid":"ead64feb-db3d-4766-a053-ba4144a2543e"},"output_config":{"id":"f9cad7b01a4721353052fd3908a6acba","src":"hda","uuid":"091f735a-6d6a-4fbf-a9e4-dd8e05f2c9b2"},"output_json":{"id":"f9cad7b01a4721352e5935f8ae5b943a","src":"hda","uuid":"7cb494f0-40de-48e3-ab76-ef0e39783b47"}},"copied_from_job_id":null,"output_collections":{},"tool_stdout":"Epoch 9/19 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                 213/426 0:01:00 â€¢ 0:00:38 5.61it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.10it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.09it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.08it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 107/107 0:00:36 â€¢ 0:00:00 2.93it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 2.97it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.81it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 107/107 0:00:36 â€¢ 0:00:00 2.91it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 107/107 0:00:35 â€¢ 0:00:00 2.87it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.00it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 2.92it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.86it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.96it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 107/107 0:00:36 â€¢ 0:00:00 2.92it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 107/107 0:00:36 â€¢ 0:00:00 2.95it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.05it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.07it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:10 â€¢ 0:00:00 3.02it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.98it/s \n","tool_stderr":"21:50:47 | INFO | === AutoGluon Training Wrapper Started ===\n21:50:47 | INFO | Working directory: /jetstream2/scratch/main/jobs/74514518/working\n21:50:47 | INFO | Command line: /jetstream2/scratch/main/jobs/74514518/tool_files/multimodal_learner.py --input_csv_train train_input.csv --input_csv_test test_input.csv --target_column 3 --sample_id_column 1 --images_zip /jetstream2/scratch/main/jobs/74514518/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat --missing_image_strategy false --backbone_image caformer_b36.sail_in22k_ft_in1k_384 --backbone_text microsoft/deberta-v3-base --preset best_quality --eval_metric roc_auc --random_seed 42 --time_limit 43200 --output_json /jetstream2/scratch/main/jobs/74514518/outputs/dataset_7cb494f0-40de-48e3-ab76-ef0e39783b47.dat --output_html /jetstream2/scratch/main/jobs/74514518/outputs/dataset_ead64feb-db3d-4766-a053-ba4144a2543e.dat --output_config /jetstream2/scratch/main/jobs/74514518/outputs/dataset_091f735a-6d6a-4fbf-a9e4-dd8e05f2c9b2.dat\n21:50:47 | INFO | Parsed args: {'train_dataset': 'train_input.csv', 'test_dataset': 'test_input.csv', 'target_column': '3', 'output_json': '/jetstream2/scratch/main/jobs/74514518/outputs/dataset_7cb494f0-40de-48e3-ab76-ef0e39783b47.dat', 'output_html': '/jetstream2/scratch/main/jobs/74514518/outputs/dataset_ead64feb-db3d-4766-a053-ba4144a2543e.dat', 'output_config': '/jetstream2/scratch/main/jobs/74514518/outputs/dataset_091f735a-6d6a-4fbf-a9e4-dd8e05f2c9b2.dat', 'images_zip': ['/jetstream2/scratch/main/jobs/74514518/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat'], 'missing_image_strategy': 'false', 'threshold': None, 'time_limit': 43200, 'deterministic': False, 'random_seed': 42, 'cross_validation': 'false', 'num_folds': 5, 'epochs': None, 'learning_rate': None, 'batch_size': None, 'num_workers': None, 'num_workers_eval': None, 'backbone_image': 'caformer_b36.sail_in22k_ft_in1k_384', 'backbone_text': 'microsoft/deberta-v3-base', 'validation_size': 0.2, 'split_probabilities': [0.7, 0.1, 0.2], 'sample_id_column': '1', 'preset': 'best_quality', 'eval_metric': 'roc_auc', 'hyperparameters': None}\n21:50:47 | INFO | Cache dirs: TORCH_HOME=./torch_cache HF_HOME=./hf_cache HUGGINGFACE_HUB_CACHE=./hf_cache/hub\n21:50:47 | INFO | Train dataset loaded: 533 rows\n21:50:47 | INFO | Test dataset loaded: 134 rows\n21:50:47 | INFO | Target column '3' not found; using column #3 header 'target' instead.\n21:50:47 | INFO | Sample ID column '1' not found; using column #1 header 'patient_id' instead.\n21:50:47 | INFO | Extracting 1 image ZIP(s) to /jetstream2/scratch/main/jobs/74514518/tmp/autogluon_images_ftchapu1\n21:55:39 | INFO | Extracted dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat\n21:55:39 | INFO | Inferred image columns: ['CD3_image_path', 'CD8_image_path']\n21:55:58 | INFO | Placeholder image created: /jetstream2/scratch/main/jobs/74514518/tmp/ag_placeholder_ub78pnz2/placeholder_76d25605df6947c5b3215b851f4e93d0.png\n21:55:59 | INFO | Filled 13 missing images with placeholder\n21:56:00 | INFO | Filled 1 missing images with placeholder\n21:56:00 | INFO | After cleanup â†’ train: 533, test: 134\n21:56:00 | INFO | External test set â†’ created val split (20%)\n21:56:00 | INFO | Final split distribution:\nsplit\ntrain    426\nval      107\nName: count, dtype: int64\n21:56:00 | INFO | Preprocessing complete â€” ready for AutoGluon training!\n21:56:00 | INFO | Final split counts:\nsplit\ntrain    426\nval      107\nName: count, dtype: int64\n21:56:00 | INFO | Using default training num_workers=8 (heuristic).\n21:56:00 | INFO | Using default inference num_workers=8 (heuristic).\n21:56:00 | INFO | AutoGluon config prepared: fit={'time_limit': 43200, 'seed': 42, 'presets': 'best_quality'}, hyperparameters keys=['env', 'model', 'env.num_workers', 'env.num_workers_inference', 'model.timm_image.checkpoint_name', 'model.hf_text.checkpoint_name']\n21:56:00 | INFO | Fitting AutoGluon with 426 train / 107 val rows (internal test rows: 0, external test provided: True)\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20260209_215600\"\n=================== System Info ===================\nAutoGluon Version:  1.4.0\nPython Version:     3.10.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sat Jan 17 14:23:47 EST 2026\nCPU Count:          16\nPytorch Version:    2.7.1+cu126\nCUDA Version:       12.6\nGPU Count:          1\nMemory Avail:       56.38 GB / 58.59 GB (96.2%)\nDisk Space Avail:   25029.37 GB / 64000.00 GB (39.1%)\n===================================================\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [np.int64(0), np.int64(1)]\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n\nAutoMM starts to create your model. âœ¨âœ¨âœ¨\n\nTo track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600\n    ```\n\nSeed set to 42\n/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n21:56:07 | INFO | Loading pretrained weights from Hugging Face hub (timm/caformer_b36.sail_in22k_ft_in1k_384)\n21:56:11 | INFO | [timm/caformer_b36.sail_in22k_ft_in1k_384] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n21:56:11 | INFO | Missing keys (head.fc.fc2.weight, head.fc.fc2.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\nGPU Count: 1\nGPU Count to be Used: 1\nGPU 0 Name: GRID A100X-20C\nGPU 0 Memory: 1.65GB/20.0GB (Used/Total)\n\nUsing 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n\n  | Name              | Type                | Params | Mode  | FLOPs\n--------------------------------------------------------------------------\n0 | model             | MultimodalFusionMLP | 282 M  | train | 0    \n1 | validation_metric | BinaryAUROC         | 0      | train | 0    \n2 | loss_func         | CrossEntropyLoss    | 0      | train | 0    \n--------------------------------------------------------------------------\n282 M     Trainable params\n0         Non-trainable params\n282 M     Total params\n1,128.083 Total estimated model params size (MB)\n1183      Modules in train mode\n0         Modules in eval mode\n0         Total Flops\n/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n  warnings.warn(*args, **kwargs)\nEpoch 0, global step 1: 'val_roc_auc' reached 0.47460 (best 0.47460), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=0-step=1.ckpt' as top 3\nEpoch 0, global step 4: 'val_roc_auc' reached 0.48316 (best 0.48316), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=0-step=4.ckpt' as top 3\nEpoch 1, global step 5: 'val_roc_auc' reached 0.40749 (best 0.48316), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=1-step=5.ckpt' as top 3\nEpoch 1, global step 8: 'val_roc_auc' reached 0.43102 (best 0.48316), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=1-step=8.ckpt' as top 3\nEpoch 2, global step 9: 'val_roc_auc' reached 0.52941 (best 0.52941), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=2-step=9.ckpt' as top 3\nEpoch 2, global step 12: 'val_roc_auc' reached 0.49358 (best 0.52941), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=2-step=12.ckpt' as top 3\nEpoch 3, global step 13: 'val_roc_auc' reached 0.50963 (best 0.52941), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=3-step=13.ckpt' as top 3\nEpoch 3, global step 16: 'val_roc_auc' reached 0.64332 (best 0.64332), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=3-step=16.ckpt' as top 3\nEpoch 4, global step 17: 'val_roc_auc' reached 0.65615 (best 0.65615), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=4-step=17.ckpt' as top 3\nEpoch 4, global step 20: 'val_roc_auc' reached 0.54251 (best 0.65615), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=4-step=20.ckpt' as top 3\nEpoch 5, global step 21: 'val_roc_auc' reached 0.60107 (best 0.65615), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=5-step=21.ckpt' as top 3\nEpoch 5, global step 24: 'val_roc_auc' was not in top 3\nEpoch 6, global step 25: 'val_roc_auc' was not in top 3\nEpoch 6, global step 28: 'val_roc_auc' was not in top 3\nEpoch 7, global step 29: 'val_roc_auc' was not in top 3\nEpoch 7, global step 32: 'val_roc_auc' was not in top 3\nEpoch 8, global step 33: 'val_roc_auc' was not in top 3\nEpoch 8, global step 36: 'val_roc_auc' was not in top 3\nEpoch 9, global step 37: 'val_roc_auc' was not in top 3\nStart to fuse 3 checkpoints via the greedy soup algorithm.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nAutoMM has created your model. ğŸ‰ğŸ‰ğŸ‰\n\nTo load the model, use the code below:\n    ```python\n    from autogluon.multimodal import MultiModalPredictor\n    predictor = MultiModalPredictor.load(\"/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600\")\n    ```\n\nIf you are not satisfied with the model, try to increase the training time, \nadjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\nor post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n\n\n22:16:53 | INFO | AutoGluon training finished. Model path: /jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n22:20:55 | INFO | Here's the model summary:The model achieved score '0.5748662948608398' on the validation metric 'roc_auc'. The total training time is 0:20:53.198044\n22:20:55 | INFO | Evaluation complete; splits: ['Train', 'Validation', 'Test']\n22:20:56 | INFO | Transparent metrics by split: {'Train': OrderedDict([('Accuracy', 0.7816901408450704), ('Precision', 0.6666666666666666), ('Recall_(Sensitivity/TPR)', 0.042105263157894736), ('F1-Score', 0.07920792079207921), ('Specificity_(TNR)', 0.9939577039274925), ('ROC-AUC', 0.7590236921609158), ('PR-AUC', 0.5099805928304911), ('LogLoss', 0.48533846576539713), ('MCC', 0.12739048311559317)]), 'Validation': OrderedDict([('Accuracy', 0.794392523364486), ('Precision', 0.0), ('Recall_(Sensitivity/TPR)', 0.0), ('F1-Score', 0.0), ('Specificity_(TNR)', 1.0), ('ROC-AUC', 0.661764705882353), ('PR-AUC', 0.3259805224080813), ('LogLoss', 0.5023230232715983), ('MCC', 0.0)]), 'Test': OrderedDict([('Accuracy', 0.753731343283582), ('Precision', 0.0), ('Recall_(Sensitivity/TPR)', 0.0), ('F1-Score', 0.0), ('Specificity_(TNR)', 1.0), ('ROC-AUC', 0.6507650765076507), ('PR-AUC', 0.3904788712518046), ('LogLoss', 0.5393123075814149), ('MCC', 0.0)])}\n22:20:56 | INFO | AutoGluon evaluate() by split: {'Train': {'roc_auc': 0.7590236921609159}, 'Validation': {'roc_auc': 0.6617647058823529}, 'Test': {'roc_auc': 0.6507650765076507}}\n22:20:56 | INFO | Wrote full JSON â†’ /jetstream2/scratch/main/jobs/74514518/outputs/dataset_7cb494f0-40de-48e3-ab76-ef0e39783b47.dat\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n22:23:34 | INFO | Wrote HTML report â†’ /jetstream2/scratch/main/jobs/74514518/outputs/dataset_ead64feb-db3d-4766-a053-ba4144a2543e.dat\n22:23:34 | INFO | Wrote predictor path â†’ predictor_path.txt\n22:23:34 | INFO | Wrote AutoGluon config â†’ /jetstream2/scratch/main/jobs/74514518/outputs/dataset_091f735a-6d6a-4fbf-a9e4-dd8e05f2c9b2.dat\n22:23:34 | INFO | âœ“ Output JSON results: /jetstream2/scratch/main/jobs/74514518/outputs/dataset_7cb494f0-40de-48e3-ab76-ef0e39783b47.dat (20,817 bytes)\n22:23:34 | INFO | âœ“ Output HTML report: /jetstream2/scratch/main/jobs/74514518/outputs/dataset_ead64feb-db3d-4766-a053-ba4144a2543e.dat (157,189 bytes)\n22:23:34 | INFO | âœ“ Output AutoGluon config: /jetstream2/scratch/main/jobs/74514518/outputs/dataset_091f735a-6d6a-4fbf-a9e4-dd8e05f2c9b2.dat (4,117 bytes)\n","job_stdout":"","job_stderr":"","stdout":"Epoch 9/19 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                 213/426 0:01:00 â€¢ 0:00:38 5.61it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.10it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.09it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.08it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 107/107 0:00:36 â€¢ 0:00:00 2.93it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 2.97it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.81it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 107/107 0:00:36 â€¢ 0:00:00 2.91it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 107/107 0:00:35 â€¢ 0:00:00 2.87it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.00it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 2.92it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.86it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.96it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 107/107 0:00:36 â€¢ 0:00:00 2.92it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 107/107 0:00:36 â€¢ 0:00:00 2.95it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.05it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.07it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:10 â€¢ 0:00:00 3.02it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.98it/s \n","stderr":"21:50:47 | INFO | === AutoGluon Training Wrapper Started ===\n21:50:47 | INFO | Working directory: /jetstream2/scratch/main/jobs/74514518/working\n21:50:47 | INFO | Command line: /jetstream2/scratch/main/jobs/74514518/tool_files/multimodal_learner.py --input_csv_train train_input.csv --input_csv_test test_input.csv --target_column 3 --sample_id_column 1 --images_zip /jetstream2/scratch/main/jobs/74514518/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat --missing_image_strategy false --backbone_image caformer_b36.sail_in22k_ft_in1k_384 --backbone_text microsoft/deberta-v3-base --preset best_quality --eval_metric roc_auc --random_seed 42 --time_limit 43200 --output_json /jetstream2/scratch/main/jobs/74514518/outputs/dataset_7cb494f0-40de-48e3-ab76-ef0e39783b47.dat --output_html /jetstream2/scratch/main/jobs/74514518/outputs/dataset_ead64feb-db3d-4766-a053-ba4144a2543e.dat --output_config /jetstream2/scratch/main/jobs/74514518/outputs/dataset_091f735a-6d6a-4fbf-a9e4-dd8e05f2c9b2.dat\n21:50:47 | INFO | Parsed args: {'train_dataset': 'train_input.csv', 'test_dataset': 'test_input.csv', 'target_column': '3', 'output_json': '/jetstream2/scratch/main/jobs/74514518/outputs/dataset_7cb494f0-40de-48e3-ab76-ef0e39783b47.dat', 'output_html': '/jetstream2/scratch/main/jobs/74514518/outputs/dataset_ead64feb-db3d-4766-a053-ba4144a2543e.dat', 'output_config': '/jetstream2/scratch/main/jobs/74514518/outputs/dataset_091f735a-6d6a-4fbf-a9e4-dd8e05f2c9b2.dat', 'images_zip': ['/jetstream2/scratch/main/jobs/74514518/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat'], 'missing_image_strategy': 'false', 'threshold': None, 'time_limit': 43200, 'deterministic': False, 'random_seed': 42, 'cross_validation': 'false', 'num_folds': 5, 'epochs': None, 'learning_rate': None, 'batch_size': None, 'num_workers': None, 'num_workers_eval': None, 'backbone_image': 'caformer_b36.sail_in22k_ft_in1k_384', 'backbone_text': 'microsoft/deberta-v3-base', 'validation_size': 0.2, 'split_probabilities': [0.7, 0.1, 0.2], 'sample_id_column': '1', 'preset': 'best_quality', 'eval_metric': 'roc_auc', 'hyperparameters': None}\n21:50:47 | INFO | Cache dirs: TORCH_HOME=./torch_cache HF_HOME=./hf_cache HUGGINGFACE_HUB_CACHE=./hf_cache/hub\n21:50:47 | INFO | Train dataset loaded: 533 rows\n21:50:47 | INFO | Test dataset loaded: 134 rows\n21:50:47 | INFO | Target column '3' not found; using column #3 header 'target' instead.\n21:50:47 | INFO | Sample ID column '1' not found; using column #1 header 'patient_id' instead.\n21:50:47 | INFO | Extracting 1 image ZIP(s) to /jetstream2/scratch/main/jobs/74514518/tmp/autogluon_images_ftchapu1\n21:55:39 | INFO | Extracted dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat\n21:55:39 | INFO | Inferred image columns: ['CD3_image_path', 'CD8_image_path']\n21:55:58 | INFO | Placeholder image created: /jetstream2/scratch/main/jobs/74514518/tmp/ag_placeholder_ub78pnz2/placeholder_76d25605df6947c5b3215b851f4e93d0.png\n21:55:59 | INFO | Filled 13 missing images with placeholder\n21:56:00 | INFO | Filled 1 missing images with placeholder\n21:56:00 | INFO | After cleanup â†’ train: 533, test: 134\n21:56:00 | INFO | External test set â†’ created val split (20%)\n21:56:00 | INFO | Final split distribution:\nsplit\ntrain    426\nval      107\nName: count, dtype: int64\n21:56:00 | INFO | Preprocessing complete â€” ready for AutoGluon training!\n21:56:00 | INFO | Final split counts:\nsplit\ntrain    426\nval      107\nName: count, dtype: int64\n21:56:00 | INFO | Using default training num_workers=8 (heuristic).\n21:56:00 | INFO | Using default inference num_workers=8 (heuristic).\n21:56:00 | INFO | AutoGluon config prepared: fit={'time_limit': 43200, 'seed': 42, 'presets': 'best_quality'}, hyperparameters keys=['env', 'model', 'env.num_workers', 'env.num_workers_inference', 'model.timm_image.checkpoint_name', 'model.hf_text.checkpoint_name']\n21:56:00 | INFO | Fitting AutoGluon with 426 train / 107 val rows (internal test rows: 0, external test provided: True)\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20260209_215600\"\n=================== System Info ===================\nAutoGluon Version:  1.4.0\nPython Version:     3.10.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sat Jan 17 14:23:47 EST 2026\nCPU Count:          16\nPytorch Version:    2.7.1+cu126\nCUDA Version:       12.6\nGPU Count:          1\nMemory Avail:       56.38 GB / 58.59 GB (96.2%)\nDisk Space Avail:   25029.37 GB / 64000.00 GB (39.1%)\n===================================================\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [np.int64(0), np.int64(1)]\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n\nAutoMM starts to create your model. âœ¨âœ¨âœ¨\n\nTo track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600\n    ```\n\nSeed set to 42\n/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n21:56:07 | INFO | Loading pretrained weights from Hugging Face hub (timm/caformer_b36.sail_in22k_ft_in1k_384)\n21:56:11 | INFO | [timm/caformer_b36.sail_in22k_ft_in1k_384] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n21:56:11 | INFO | Missing keys (head.fc.fc2.weight, head.fc.fc2.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\nGPU Count: 1\nGPU Count to be Used: 1\nGPU 0 Name: GRID A100X-20C\nGPU 0 Memory: 1.65GB/20.0GB (Used/Total)\n\nUsing 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n\n  | Name              | Type                | Params | Mode  | FLOPs\n--------------------------------------------------------------------------\n0 | model             | MultimodalFusionMLP | 282 M  | train | 0    \n1 | validation_metric | BinaryAUROC         | 0      | train | 0    \n2 | loss_func         | CrossEntropyLoss    | 0      | train | 0    \n--------------------------------------------------------------------------\n282 M     Trainable params\n0         Non-trainable params\n282 M     Total params\n1,128.083 Total estimated model params size (MB)\n1183      Modules in train mode\n0         Modules in eval mode\n0         Total Flops\n/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n  warnings.warn(*args, **kwargs)\nEpoch 0, global step 1: 'val_roc_auc' reached 0.47460 (best 0.47460), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=0-step=1.ckpt' as top 3\nEpoch 0, global step 4: 'val_roc_auc' reached 0.48316 (best 0.48316), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=0-step=4.ckpt' as top 3\nEpoch 1, global step 5: 'val_roc_auc' reached 0.40749 (best 0.48316), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=1-step=5.ckpt' as top 3\nEpoch 1, global step 8: 'val_roc_auc' reached 0.43102 (best 0.48316), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=1-step=8.ckpt' as top 3\nEpoch 2, global step 9: 'val_roc_auc' reached 0.52941 (best 0.52941), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=2-step=9.ckpt' as top 3\nEpoch 2, global step 12: 'val_roc_auc' reached 0.49358 (best 0.52941), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=2-step=12.ckpt' as top 3\nEpoch 3, global step 13: 'val_roc_auc' reached 0.50963 (best 0.52941), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=3-step=13.ckpt' as top 3\nEpoch 3, global step 16: 'val_roc_auc' reached 0.64332 (best 0.64332), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=3-step=16.ckpt' as top 3\nEpoch 4, global step 17: 'val_roc_auc' reached 0.65615 (best 0.65615), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=4-step=17.ckpt' as top 3\nEpoch 4, global step 20: 'val_roc_auc' reached 0.54251 (best 0.65615), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=4-step=20.ckpt' as top 3\nEpoch 5, global step 21: 'val_roc_auc' reached 0.60107 (best 0.65615), saving model to '/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600/epoch=5-step=21.ckpt' as top 3\nEpoch 5, global step 24: 'val_roc_auc' was not in top 3\nEpoch 6, global step 25: 'val_roc_auc' was not in top 3\nEpoch 6, global step 28: 'val_roc_auc' was not in top 3\nEpoch 7, global step 29: 'val_roc_auc' was not in top 3\nEpoch 7, global step 32: 'val_roc_auc' was not in top 3\nEpoch 8, global step 33: 'val_roc_auc' was not in top 3\nEpoch 8, global step 36: 'val_roc_auc' was not in top 3\nEpoch 9, global step 37: 'val_roc_auc' was not in top 3\nStart to fuse 3 checkpoints via the greedy soup algorithm.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nAutoMM has created your model. ğŸ‰ğŸ‰ğŸ‰\n\nTo load the model, use the code below:\n    ```python\n    from autogluon.multimodal import MultiModalPredictor\n    predictor = MultiModalPredictor.load(\"/jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600\")\n    ```\n\nIf you are not satisfied with the model, try to increase the training time, \nadjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\nor post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n\n\n22:16:53 | INFO | AutoGluon training finished. Model path: /jetstream2/scratch/main/jobs/74514518/working/AutogluonModels/ag-20260209_215600\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n22:20:55 | INFO | Here's the model summary:The model achieved score '0.5748662948608398' on the validation metric 'roc_auc'. The total training time is 0:20:53.198044\n22:20:55 | INFO | Evaluation complete; splits: ['Train', 'Validation', 'Test']\n22:20:56 | INFO | Transparent metrics by split: {'Train': OrderedDict([('Accuracy', 0.7816901408450704), ('Precision', 0.6666666666666666), ('Recall_(Sensitivity/TPR)', 0.042105263157894736), ('F1-Score', 0.07920792079207921), ('Specificity_(TNR)', 0.9939577039274925), ('ROC-AUC', 0.7590236921609158), ('PR-AUC', 0.5099805928304911), ('LogLoss', 0.48533846576539713), ('MCC', 0.12739048311559317)]), 'Validation': OrderedDict([('Accuracy', 0.794392523364486), ('Precision', 0.0), ('Recall_(Sensitivity/TPR)', 0.0), ('F1-Score', 0.0), ('Specificity_(TNR)', 1.0), ('ROC-AUC', 0.661764705882353), ('PR-AUC', 0.3259805224080813), ('LogLoss', 0.5023230232715983), ('MCC', 0.0)]), 'Test': OrderedDict([('Accuracy', 0.753731343283582), ('Precision', 0.0), ('Recall_(Sensitivity/TPR)', 0.0), ('F1-Score', 0.0), ('Specificity_(TNR)', 1.0), ('ROC-AUC', 0.6507650765076507), ('PR-AUC', 0.3904788712518046), ('LogLoss', 0.5393123075814149), ('MCC', 0.0)])}\n22:20:56 | INFO | AutoGluon evaluate() by split: {'Train': {'roc_auc': 0.7590236921609159}, 'Validation': {'roc_auc': 0.6617647058823529}, 'Test': {'roc_auc': 0.6507650765076507}}\n22:20:56 | INFO | Wrote full JSON â†’ /jetstream2/scratch/main/jobs/74514518/outputs/dataset_7cb494f0-40de-48e3-ab76-ef0e39783b47.dat\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n22:23:34 | INFO | Wrote HTML report â†’ /jetstream2/scratch/main/jobs/74514518/outputs/dataset_ead64feb-db3d-4766-a053-ba4144a2543e.dat\n22:23:34 | INFO | Wrote predictor path â†’ predictor_path.txt\n22:23:34 | INFO | Wrote AutoGluon config â†’ /jetstream2/scratch/main/jobs/74514518/outputs/dataset_091f735a-6d6a-4fbf-a9e4-dd8e05f2c9b2.dat\n22:23:34 | INFO | âœ“ Output JSON results: /jetstream2/scratch/main/jobs/74514518/outputs/dataset_7cb494f0-40de-48e3-ab76-ef0e39783b47.dat (20,817 bytes)\n22:23:34 | INFO | âœ“ Output HTML report: /jetstream2/scratch/main/jobs/74514518/outputs/dataset_ead64feb-db3d-4766-a053-ba4144a2543e.dat (157,189 bytes)\n22:23:34 | INFO | âœ“ Output AutoGluon config: /jetstream2/scratch/main/jobs/74514518/outputs/dataset_091f735a-6d6a-4fbf-a9e4-dd8e05f2c9b2.dat (4,117 bytes)\n","job_messages":[],"dependencies":[],"job_metrics":null}
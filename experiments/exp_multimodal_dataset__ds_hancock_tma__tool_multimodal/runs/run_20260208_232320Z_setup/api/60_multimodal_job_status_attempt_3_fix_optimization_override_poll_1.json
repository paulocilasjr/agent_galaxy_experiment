{"model_class":"Job","id":"bbd44e69cb8906b5fbd5ff2ad8f177dd","history_id":"bbd44e69cb8906b5ce223e9a81174ae0","tool_id":"toolshed.g2.bx.psu.edu/repos/goeckslab/multimodal_learner/multimodal_learner/0.1.5","state":"ok","exit_code":0,"create_time":"2026-02-09T16:38:23.405232","update_time":"2026-02-09T20:12:30.339116","galaxy_version":"25.1","external_id":null,"handler":null,"job_runner_name":null,"command_line":"set -e; ln -sf '/jetstream2/scratch/main/jobs/74504199/inputs/dataset_bed0da13-577a-4094-bb36-e678609c48ff.dat' 'train_input.csv'; ln -sf '/jetstream2/scratch/main/jobs/74504199/inputs/dataset_8afe987e-6cca-49ac-a972-45ab1376c13d.dat' 'test_input.csv';  export TORCH_HOME=\"./torch_cache\" && export HF_HOME=\"./hf_cache\" && export HUGGINGFACE_HUB_CACHE=\"./hf_cache/hub\" && mkdir -p \"./torch_cache\" \"./hf_cache/hub\" &&  python '/jetstream2/scratch/main/jobs/74504199/tool_files/multimodal_learner.py' --input_csv_train 'train_input.csv' --input_csv_test 'test_input.csv' --target_column '3' --sample_id_column '1'  --images_zip '/jetstream2/scratch/main/jobs/74504199/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat' --missing_image_strategy 'true' --backbone_image 'caformer_s18.sail_in22k_ft_in1k'  --backbone_text 'microsoft/deberta-v3-base'  --preset 'best_quality' --eval_metric 'roc_auc'  --random_seed '42' --time_limit 21600   --output_json '/jetstream2/scratch/main/jobs/74504199/outputs/dataset_2d183589-25c2-4790-b2fa-caa57ab4ec3c.dat' --output_html '/jetstream2/scratch/main/jobs/74504199/outputs/dataset_76884e07-6717-41c8-a70a-ff0b91598771.dat' --output_config '/jetstream2/scratch/main/jobs/74504199/outputs/dataset_f5863c60-cfc2-4b85-8214-064db1705fbc.dat'","user_email":null,"user_id":"92401dda9a0b9e33","command_version":"","params":{"target_column":"\"3\"","sample_id_selector":"{\"__current_case__\": 0, \"sample_id_column\": \"1\", \"use_sample_id\": \"yes\"}","test_dataset_conditional":"{\"__current_case__\": 0, \"has_test_dataset\": true, \"input_test\": {\"values\": [{\"id\": 168376039, \"src\": \"hda\"}]}}","backbone_text":"\"microsoft/deberta-v3-base\"","use_images_conditional":"{\"__current_case__\": 0, \"backbone_image\": \"caformer_s18.sail_in22k_ft_in1k\", \"images_zip_repeat\": [{\"__index__\": 0, \"images_zip\": {\"values\": [{\"id\": 168376040, \"src\": \"hda\"}]}}], \"missing_image_strategy\": true, \"use_images\": true}","preset":"\"best_quality\"","eval_metric":"\"roc_auc\"","random_seed":"\"42\"","time_limit":"\"21600\"","deterministic":"false","customize_defaults_conditional":"{\"__current_case__\": 1, \"customize_defaults\": false}","chromInfo":"\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"","dbkey":"\"?\"","__input_ext":"\"input\""},"inputs":{"input_csv":{"id":"f9cad7b01a472135214deb0f5acedc0b","src":"hda","uuid":"bed0da13-577a-4094-bb36-e678609c48ff"},"test_dataset_conditional|input_test":{"id":"f9cad7b01a4721356b6decc42b7e78f0","src":"hda","uuid":"8afe987e-6cca-49ac-a972-45ab1376c13d"},"use_images_conditional|images_zip_repeat_0|images_zip":{"id":"f9cad7b01a4721357c0e9f7ba4c68487","src":"hda","uuid":"666b7df2-0818-43d9-b778-cb5a83c8cdcd"}},"outputs":{"output_html":{"id":"f9cad7b01a47213556bb211dbf607a26","src":"hda","uuid":"76884e07-6717-41c8-a70a-ff0b91598771"},"output_config":{"id":"f9cad7b01a472135c8b9337d98ad4e06","src":"hda","uuid":"f5863c60-cfc2-4b85-8214-064db1705fbc"},"output_json":{"id":"f9cad7b01a472135d6130d4a14671260","src":"hda","uuid":"2d183589-25c2-4790-b2fa-caa57ab4ec3c"}},"copied_from_job_id":null,"output_collections":{},"tool_stdout":"Epoch 14/19 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                 207/415 0:00:47 â€¢ 0:00:28 7.43it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.25it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.04it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.26it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104/104 0:00:33 â€¢ 0:00:00 3.08it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.11it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.92it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104/104 0:00:33 â€¢ 0:00:00 3.13it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104/104 0:00:32 â€¢ 0:00:00 3.14it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.06it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.21it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.88it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:10 â€¢ 0:00:00 3.10it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104/104 0:00:32 â€¢ 0:00:00 3.07it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104/104 0:00:33 â€¢ 0:00:00 3.12it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.06it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.05it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 3.01it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:10 â€¢ 0:00:00 3.24it/s \n","tool_stderr":"19:34:58 | INFO | === AutoGluon Training Wrapper Started ===\n19:34:58 | INFO | Working directory: /jetstream2/scratch/main/jobs/74504199/working\n19:34:58 | INFO | Command line: /jetstream2/scratch/main/jobs/74504199/tool_files/multimodal_learner.py --input_csv_train train_input.csv --input_csv_test test_input.csv --target_column 3 --sample_id_column 1 --images_zip /jetstream2/scratch/main/jobs/74504199/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat --missing_image_strategy true --backbone_image caformer_s18.sail_in22k_ft_in1k --backbone_text microsoft/deberta-v3-base --preset best_quality --eval_metric roc_auc --random_seed 42 --time_limit 21600 --output_json /jetstream2/scratch/main/jobs/74504199/outputs/dataset_2d183589-25c2-4790-b2fa-caa57ab4ec3c.dat --output_html /jetstream2/scratch/main/jobs/74504199/outputs/dataset_76884e07-6717-41c8-a70a-ff0b91598771.dat --output_config /jetstream2/scratch/main/jobs/74504199/outputs/dataset_f5863c60-cfc2-4b85-8214-064db1705fbc.dat\n19:34:58 | INFO | Parsed args: {'train_dataset': 'train_input.csv', 'test_dataset': 'test_input.csv', 'target_column': '3', 'output_json': '/jetstream2/scratch/main/jobs/74504199/outputs/dataset_2d183589-25c2-4790-b2fa-caa57ab4ec3c.dat', 'output_html': '/jetstream2/scratch/main/jobs/74504199/outputs/dataset_76884e07-6717-41c8-a70a-ff0b91598771.dat', 'output_config': '/jetstream2/scratch/main/jobs/74504199/outputs/dataset_f5863c60-cfc2-4b85-8214-064db1705fbc.dat', 'images_zip': ['/jetstream2/scratch/main/jobs/74504199/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat'], 'missing_image_strategy': 'true', 'threshold': None, 'time_limit': 21600, 'deterministic': False, 'random_seed': 42, 'cross_validation': 'false', 'num_folds': 5, 'epochs': None, 'learning_rate': None, 'batch_size': None, 'num_workers': None, 'num_workers_eval': None, 'backbone_image': 'caformer_s18.sail_in22k_ft_in1k', 'backbone_text': 'microsoft/deberta-v3-base', 'validation_size': 0.2, 'split_probabilities': [0.7, 0.1, 0.2], 'sample_id_column': '1', 'preset': 'best_quality', 'eval_metric': 'roc_auc', 'hyperparameters': None}\n19:34:58 | INFO | Cache dirs: TORCH_HOME=./torch_cache HF_HOME=./hf_cache HUGGINGFACE_HUB_CACHE=./hf_cache/hub\n19:34:58 | INFO | Train dataset loaded: 533 rows\n19:34:58 | INFO | Test dataset loaded: 134 rows\n19:34:58 | INFO | Target column '3' not found; using column #3 header 'target' instead.\n19:34:58 | INFO | Sample ID column '1' not found; using column #1 header 'patient_id' instead.\n19:34:58 | INFO | Extracting 1 image ZIP(s) to /jetstream2/scratch/main/jobs/74504199/tmp/autogluon_images_fc9secbt\n19:40:01 | INFO | Extracted dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat\n19:40:02 | INFO | Inferred image columns: ['CD3_image_path', 'CD8_image_path']\n19:40:21 | INFO | Dropped 13 rows with missing images â†’ 520 remain\n19:40:21 | INFO | Dropped 1 rows with missing images â†’ 133 remain\n19:40:21 | INFO | After cleanup â†’ train: 520, test: 133\n19:40:21 | INFO | External test set â†’ created val split (20%)\n19:40:21 | INFO | Final split distribution:\nsplit\ntrain    415\nval      105\nName: count, dtype: int64\n19:40:21 | INFO | Preprocessing complete â€” ready for AutoGluon training!\n19:40:21 | INFO | Final split counts:\nsplit\ntrain    415\nval      105\nName: count, dtype: int64\n19:40:21 | INFO | Using default training num_workers=8 (heuristic).\n19:40:21 | INFO | Using default inference num_workers=8 (heuristic).\n19:40:21 | INFO | AutoGluon config prepared: fit={'time_limit': 21600, 'seed': 42, 'presets': 'best_quality'}, hyperparameters keys=['env', 'model', 'env.num_workers', 'env.num_workers_inference', 'model.timm_image.checkpoint_name', 'model.hf_text.checkpoint_name']\n19:40:21 | INFO | Fitting AutoGluon with 415 train / 105 val rows (internal test rows: 0, external test provided: True)\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20260209_194021\"\n=================== System Info ===================\nAutoGluon Version:  1.4.0\nPython Version:     3.10.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sat Jan 17 14:23:47 EST 2026\nCPU Count:          16\nPytorch Version:    2.7.1+cu126\nCUDA Version:       12.6\nGPU Count:          1\nMemory Avail:       56.40 GB / 58.59 GB (96.3%)\nDisk Space Avail:   26535.77 GB / 64000.00 GB (41.5%)\n===================================================\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [np.int64(0), np.int64(1)]\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n\nAutoMM starts to create your model. âœ¨âœ¨âœ¨\n\nTo track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021\n    ```\n\nSeed set to 42\n/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n19:40:27 | INFO | Loading pretrained weights from Hugging Face hub (timm/caformer_s18.sail_in22k_ft_in1k)\n19:40:29 | INFO | [timm/caformer_s18.sail_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n19:40:29 | INFO | Missing keys (head.fc.fc2.weight, head.fc.fc2.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\nGPU Count: 1\nGPU Count to be Used: 1\nGPU 0 Name: GRID A100X-20C\nGPU 0 Memory: 1.65GB/20.0GB (Used/Total)\n\nUsing 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n\n  | Name              | Type                | Params | Mode  | FLOPs\n--------------------------------------------------------------------------\n0 | model             | MultimodalFusionMLP | 210 M  | train | 0    \n1 | validation_metric | BinaryAUROC         | 0      | train | 0    \n2 | loss_func         | CrossEntropyLoss    | 0      | train | 0    \n--------------------------------------------------------------------------\n210 M     Trainable params\n0         Non-trainable params\n210 M     Total params\n841.738   Total estimated model params size (MB)\n769       Modules in train mode\n0         Modules in eval mode\n0         Total Flops\n/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n  warnings.warn(*args, **kwargs)\nEpoch 0, global step 1: 'val_roc_auc' reached 0.34650 (best 0.34650), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=0-step=1.ckpt' as top 3\nEpoch 0, global step 3: 'val_roc_auc' reached 0.59279 (best 0.59279), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=0-step=3.ckpt' as top 3\nEpoch 1, global step 5: 'val_roc_auc' reached 0.61850 (best 0.61850), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=1-step=5.ckpt' as top 3\nEpoch 1, global step 7: 'val_roc_auc' reached 0.55249 (best 0.61850), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=1-step=7.ckpt' as top 3\nEpoch 2, global step 9: 'val_roc_auc' reached 0.64316 (best 0.64316), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=2-step=9.ckpt' as top 3\nEpoch 2, global step 11: 'val_roc_auc' reached 0.60233 (best 0.64316), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=2-step=11.ckpt' as top 3\nEpoch 3, global step 13: 'val_roc_auc' reached 0.60923 (best 0.64316), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=3-step=13.ckpt' as top 3\nEpoch 3, global step 15: 'val_roc_auc' was not in top 3\nEpoch 4, global step 17: 'val_roc_auc' reached 0.62116 (best 0.64316), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=4-step=17.ckpt' as top 3\nEpoch 4, global step 19: 'val_roc_auc' reached 0.65482 (best 0.65482), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=4-step=19.ckpt' as top 3\nEpoch 5, global step 21: 'val_roc_auc' reached 0.74708 (best 0.74708), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=5-step=21.ckpt' as top 3\nEpoch 5, global step 23: 'val_roc_auc' reached 0.75769 (best 0.75769), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=5-step=23.ckpt' as top 3\nEpoch 6, global step 25: 'val_roc_auc' reached 0.72641 (best 0.75769), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=6-step=25.ckpt' as top 3\nEpoch 6, global step 27: 'val_roc_auc' reached 0.72747 (best 0.75769), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=6-step=27.ckpt' as top 3\nEpoch 7, global step 29: 'val_roc_auc' reached 0.74602 (best 0.75769), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=7-step=29.ckpt' as top 3\nEpoch 7, global step 31: 'val_roc_auc' reached 0.78314 (best 0.78314), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=7-step=31.ckpt' as top 3\nEpoch 8, global step 33: 'val_roc_auc' reached 0.78579 (best 0.78579), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=8-step=33.ckpt' as top 3\nEpoch 8, global step 35: 'val_roc_auc' reached 0.80488 (best 0.80488), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=8-step=35.ckpt' as top 3\nEpoch 9, global step 37: 'val_roc_auc' reached 0.80806 (best 0.80806), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=9-step=37.ckpt' as top 3\nEpoch 9, global step 39: 'val_roc_auc' reached 0.79083 (best 0.80806), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=9-step=39.ckpt' as top 3\nEpoch 10, global step 41: 'val_roc_auc' was not in top 3\nEpoch 10, global step 43: 'val_roc_auc' was not in top 3\nEpoch 11, global step 45: 'val_roc_auc' was not in top 3\nEpoch 11, global step 47: 'val_roc_auc' was not in top 3\nEpoch 12, global step 49: 'val_roc_auc' was not in top 3\nEpoch 12, global step 51: 'val_roc_auc' was not in top 3\nEpoch 13, global step 53: 'val_roc_auc' was not in top 3\nEpoch 13, global step 55: 'val_roc_auc' was not in top 3\nEpoch 14, global step 57: 'val_roc_auc' was not in top 3\nStart to fuse 3 checkpoints via the greedy soup algorithm.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nAutoMM has created your model. ğŸ‰ğŸ‰ğŸ‰\n\nTo load the model, use the code below:\n    ```python\n    from autogluon.multimodal import MultiModalPredictor\n    predictor = MultiModalPredictor.load(\"/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021\")\n    ```\n\nIf you are not satisfied with the model, try to increase the training time, \nadjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\nor post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n\n\n20:05:42 | INFO | AutoGluon training finished. Model path: /jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n20:09:19 | INFO | Here's the model summary:The model achieved score '0.7725344300270081' on the validation metric 'roc_auc'. The total training time is 0:25:20.979108\n20:09:19 | INFO | Evaluation complete; splits: ['Train', 'Validation', 'Test']\n20:09:19 | INFO | Transparent metrics by split: {'Train': OrderedDict([('Accuracy', 0.8530120481927711), ('Precision', 0.9375), ('Recall_(Sensitivity/TPR)', 0.33707865168539325), ('F1-Score', 0.49586776859504134), ('Specificity_(TNR)', 0.9938650306748467), ('ROC-AUC', 0.874543323912594), ('PR-AUC', 0.7271284566783014), ('LogLoss', 0.35627096542118075), ('MCC', 0.509194286731754)]), 'Validation': OrderedDict([('Accuracy', 0.8), ('Precision', 0.75), ('Recall_(Sensitivity/TPR)', 0.13043478260869565), ('F1-Score', 0.2222222222222222), ('Specificity_(TNR)', 0.9878048780487805), ('ROC-AUC', 0.8085896076352068), ('PR-AUC', 0.548320021533651), ('LogLoss', 0.432463694060989), ('MCC', 0.2554720166740535)]), 'Test': OrderedDict([('Accuracy', 0.7894736842105263), ('Precision', 0.8571428571428571), ('Recall_(Sensitivity/TPR)', 0.18181818181818182), ('F1-Score', 0.3), ('Specificity_(TNR)', 0.99), ('ROC-AUC', 0.7693939393939394), ('PR-AUC', 0.5859232921106323), ('LogLoss', 0.478200485483861), ('MCC', 0.3323470256441984)])}\n20:09:19 | INFO | AutoGluon evaluate() by split: {'Train': {'roc_auc': 0.8745433239125939}, 'Validation': {'roc_auc': 0.8085896076352068}, 'Test': {'roc_auc': 0.7693939393939393}}\n20:09:19 | INFO | Wrote full JSON â†’ /jetstream2/scratch/main/jobs/74504199/outputs/dataset_2d183589-25c2-4790-b2fa-caa57ab4ec3c.dat\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n20:11:41 | INFO | Wrote HTML report â†’ /jetstream2/scratch/main/jobs/74504199/outputs/dataset_76884e07-6717-41c8-a70a-ff0b91598771.dat\n20:11:41 | INFO | Wrote predictor path â†’ predictor_path.txt\n20:11:41 | INFO | Wrote AutoGluon config â†’ /jetstream2/scratch/main/jobs/74504199/outputs/dataset_f5863c60-cfc2-4b85-8214-064db1705fbc.dat\n20:11:41 | INFO | âœ“ Output JSON results: /jetstream2/scratch/main/jobs/74504199/outputs/dataset_2d183589-25c2-4790-b2fa-caa57ab4ec3c.dat (15,942 bytes)\n20:11:41 | INFO | âœ“ Output HTML report: /jetstream2/scratch/main/jobs/74504199/outputs/dataset_76884e07-6717-41c8-a70a-ff0b91598771.dat (156,875 bytes)\n20:11:41 | INFO | âœ“ Output AutoGluon config: /jetstream2/scratch/main/jobs/74504199/outputs/dataset_f5863c60-cfc2-4b85-8214-064db1705fbc.dat (4,113 bytes)\n","job_stdout":"","job_stderr":"","stdout":"Epoch 14/19 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”                 207/415 0:00:47 â€¢ 0:00:28 7.43it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.25it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.04it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.26it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104/104 0:00:33 â€¢ 0:00:00 3.08it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.11it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.92it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104/104 0:00:33 â€¢ 0:00:00 3.13it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104/104 0:00:32 â€¢ 0:00:00 3.14it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.06it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.21it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 2.88it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:10 â€¢ 0:00:00 3.10it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104/104 0:00:32 â€¢ 0:00:00 3.07it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 104/104 0:00:33 â€¢ 0:00:00 3.12it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.06it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 27/27 0:00:08 â€¢ 0:00:00 3.05it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:11 â€¢ 0:00:00 3.01it/s \nPredicting â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 34/34 0:00:10 â€¢ 0:00:00 3.24it/s \n","stderr":"19:34:58 | INFO | === AutoGluon Training Wrapper Started ===\n19:34:58 | INFO | Working directory: /jetstream2/scratch/main/jobs/74504199/working\n19:34:58 | INFO | Command line: /jetstream2/scratch/main/jobs/74504199/tool_files/multimodal_learner.py --input_csv_train train_input.csv --input_csv_test test_input.csv --target_column 3 --sample_id_column 1 --images_zip /jetstream2/scratch/main/jobs/74504199/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat --missing_image_strategy true --backbone_image caformer_s18.sail_in22k_ft_in1k --backbone_text microsoft/deberta-v3-base --preset best_quality --eval_metric roc_auc --random_seed 42 --time_limit 21600 --output_json /jetstream2/scratch/main/jobs/74504199/outputs/dataset_2d183589-25c2-4790-b2fa-caa57ab4ec3c.dat --output_html /jetstream2/scratch/main/jobs/74504199/outputs/dataset_76884e07-6717-41c8-a70a-ff0b91598771.dat --output_config /jetstream2/scratch/main/jobs/74504199/outputs/dataset_f5863c60-cfc2-4b85-8214-064db1705fbc.dat\n19:34:58 | INFO | Parsed args: {'train_dataset': 'train_input.csv', 'test_dataset': 'test_input.csv', 'target_column': '3', 'output_json': '/jetstream2/scratch/main/jobs/74504199/outputs/dataset_2d183589-25c2-4790-b2fa-caa57ab4ec3c.dat', 'output_html': '/jetstream2/scratch/main/jobs/74504199/outputs/dataset_76884e07-6717-41c8-a70a-ff0b91598771.dat', 'output_config': '/jetstream2/scratch/main/jobs/74504199/outputs/dataset_f5863c60-cfc2-4b85-8214-064db1705fbc.dat', 'images_zip': ['/jetstream2/scratch/main/jobs/74504199/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat'], 'missing_image_strategy': 'true', 'threshold': None, 'time_limit': 21600, 'deterministic': False, 'random_seed': 42, 'cross_validation': 'false', 'num_folds': 5, 'epochs': None, 'learning_rate': None, 'batch_size': None, 'num_workers': None, 'num_workers_eval': None, 'backbone_image': 'caformer_s18.sail_in22k_ft_in1k', 'backbone_text': 'microsoft/deberta-v3-base', 'validation_size': 0.2, 'split_probabilities': [0.7, 0.1, 0.2], 'sample_id_column': '1', 'preset': 'best_quality', 'eval_metric': 'roc_auc', 'hyperparameters': None}\n19:34:58 | INFO | Cache dirs: TORCH_HOME=./torch_cache HF_HOME=./hf_cache HUGGINGFACE_HUB_CACHE=./hf_cache/hub\n19:34:58 | INFO | Train dataset loaded: 533 rows\n19:34:58 | INFO | Test dataset loaded: 134 rows\n19:34:58 | INFO | Target column '3' not found; using column #3 header 'target' instead.\n19:34:58 | INFO | Sample ID column '1' not found; using column #1 header 'patient_id' instead.\n19:34:58 | INFO | Extracting 1 image ZIP(s) to /jetstream2/scratch/main/jobs/74504199/tmp/autogluon_images_fc9secbt\n19:40:01 | INFO | Extracted dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat\n19:40:02 | INFO | Inferred image columns: ['CD3_image_path', 'CD8_image_path']\n19:40:21 | INFO | Dropped 13 rows with missing images â†’ 520 remain\n19:40:21 | INFO | Dropped 1 rows with missing images â†’ 133 remain\n19:40:21 | INFO | After cleanup â†’ train: 520, test: 133\n19:40:21 | INFO | External test set â†’ created val split (20%)\n19:40:21 | INFO | Final split distribution:\nsplit\ntrain    415\nval      105\nName: count, dtype: int64\n19:40:21 | INFO | Preprocessing complete â€” ready for AutoGluon training!\n19:40:21 | INFO | Final split counts:\nsplit\ntrain    415\nval      105\nName: count, dtype: int64\n19:40:21 | INFO | Using default training num_workers=8 (heuristic).\n19:40:21 | INFO | Using default inference num_workers=8 (heuristic).\n19:40:21 | INFO | AutoGluon config prepared: fit={'time_limit': 21600, 'seed': 42, 'presets': 'best_quality'}, hyperparameters keys=['env', 'model', 'env.num_workers', 'env.num_workers_inference', 'model.timm_image.checkpoint_name', 'model.hf_text.checkpoint_name']\n19:40:21 | INFO | Fitting AutoGluon with 415 train / 105 val rows (internal test rows: 0, external test provided: True)\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20260209_194021\"\n=================== System Info ===================\nAutoGluon Version:  1.4.0\nPython Version:     3.10.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sat Jan 17 14:23:47 EST 2026\nCPU Count:          16\nPytorch Version:    2.7.1+cu126\nCUDA Version:       12.6\nGPU Count:          1\nMemory Avail:       56.40 GB / 58.59 GB (96.3%)\nDisk Space Avail:   26535.77 GB / 64000.00 GB (41.5%)\n===================================================\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [np.int64(0), np.int64(1)]\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n\nAutoMM starts to create your model. âœ¨âœ¨âœ¨\n\nTo track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021\n    ```\n\nSeed set to 42\n/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n19:40:27 | INFO | Loading pretrained weights from Hugging Face hub (timm/caformer_s18.sail_in22k_ft_in1k)\n19:40:29 | INFO | [timm/caformer_s18.sail_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n19:40:29 | INFO | Missing keys (head.fc.fc2.weight, head.fc.fc2.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\nGPU Count: 1\nGPU Count to be Used: 1\nGPU 0 Name: GRID A100X-20C\nGPU 0 Memory: 1.65GB/20.0GB (Used/Total)\n\nUsing 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nLOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.\n\n  | Name              | Type                | Params | Mode  | FLOPs\n--------------------------------------------------------------------------\n0 | model             | MultimodalFusionMLP | 210 M  | train | 0    \n1 | validation_metric | BinaryAUROC         | 0      | train | 0    \n2 | loss_func         | CrossEntropyLoss    | 0      | train | 0    \n--------------------------------------------------------------------------\n210 M     Trainable params\n0         Non-trainable params\n210 M     Total params\n841.738   Total estimated model params size (MB)\n769       Modules in train mode\n0         Modules in eval mode\n0         Total Flops\n/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n  warnings.warn(*args, **kwargs)\nEpoch 0, global step 1: 'val_roc_auc' reached 0.34650 (best 0.34650), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=0-step=1.ckpt' as top 3\nEpoch 0, global step 3: 'val_roc_auc' reached 0.59279 (best 0.59279), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=0-step=3.ckpt' as top 3\nEpoch 1, global step 5: 'val_roc_auc' reached 0.61850 (best 0.61850), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=1-step=5.ckpt' as top 3\nEpoch 1, global step 7: 'val_roc_auc' reached 0.55249 (best 0.61850), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=1-step=7.ckpt' as top 3\nEpoch 2, global step 9: 'val_roc_auc' reached 0.64316 (best 0.64316), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=2-step=9.ckpt' as top 3\nEpoch 2, global step 11: 'val_roc_auc' reached 0.60233 (best 0.64316), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=2-step=11.ckpt' as top 3\nEpoch 3, global step 13: 'val_roc_auc' reached 0.60923 (best 0.64316), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=3-step=13.ckpt' as top 3\nEpoch 3, global step 15: 'val_roc_auc' was not in top 3\nEpoch 4, global step 17: 'val_roc_auc' reached 0.62116 (best 0.64316), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=4-step=17.ckpt' as top 3\nEpoch 4, global step 19: 'val_roc_auc' reached 0.65482 (best 0.65482), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=4-step=19.ckpt' as top 3\nEpoch 5, global step 21: 'val_roc_auc' reached 0.74708 (best 0.74708), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=5-step=21.ckpt' as top 3\nEpoch 5, global step 23: 'val_roc_auc' reached 0.75769 (best 0.75769), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=5-step=23.ckpt' as top 3\nEpoch 6, global step 25: 'val_roc_auc' reached 0.72641 (best 0.75769), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=6-step=25.ckpt' as top 3\nEpoch 6, global step 27: 'val_roc_auc' reached 0.72747 (best 0.75769), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=6-step=27.ckpt' as top 3\nEpoch 7, global step 29: 'val_roc_auc' reached 0.74602 (best 0.75769), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=7-step=29.ckpt' as top 3\nEpoch 7, global step 31: 'val_roc_auc' reached 0.78314 (best 0.78314), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=7-step=31.ckpt' as top 3\nEpoch 8, global step 33: 'val_roc_auc' reached 0.78579 (best 0.78579), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=8-step=33.ckpt' as top 3\nEpoch 8, global step 35: 'val_roc_auc' reached 0.80488 (best 0.80488), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=8-step=35.ckpt' as top 3\nEpoch 9, global step 37: 'val_roc_auc' reached 0.80806 (best 0.80806), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=9-step=37.ckpt' as top 3\nEpoch 9, global step 39: 'val_roc_auc' reached 0.79083 (best 0.80806), saving model to '/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021/epoch=9-step=39.ckpt' as top 3\nEpoch 10, global step 41: 'val_roc_auc' was not in top 3\nEpoch 10, global step 43: 'val_roc_auc' was not in top 3\nEpoch 11, global step 45: 'val_roc_auc' was not in top 3\nEpoch 11, global step 47: 'val_roc_auc' was not in top 3\nEpoch 12, global step 49: 'val_roc_auc' was not in top 3\nEpoch 12, global step 51: 'val_roc_auc' was not in top 3\nEpoch 13, global step 53: 'val_roc_auc' was not in top 3\nEpoch 13, global step 55: 'val_roc_auc' was not in top 3\nEpoch 14, global step 57: 'val_roc_auc' was not in top 3\nStart to fuse 3 checkpoints via the greedy soup algorithm.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nAutoMM has created your model. ğŸ‰ğŸ‰ğŸ‰\n\nTo load the model, use the code below:\n    ```python\n    from autogluon.multimodal import MultiModalPredictor\n    predictor = MultiModalPredictor.load(\"/jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021\")\n    ```\n\nIf you are not satisfied with the model, try to increase the training time, \nadjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\nor post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n\n\n20:05:42 | INFO | AutoGluon training finished. Model path: /jetstream2/scratch/main/jobs/74504199/working/AutogluonModels/ag-20260209_194021\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n20:09:19 | INFO | Here's the model summary:The model achieved score '0.7725344300270081' on the validation metric 'roc_auc'. The total training time is 0:25:20.979108\n20:09:19 | INFO | Evaluation complete; splits: ['Train', 'Validation', 'Test']\n20:09:19 | INFO | Transparent metrics by split: {'Train': OrderedDict([('Accuracy', 0.8530120481927711), ('Precision', 0.9375), ('Recall_(Sensitivity/TPR)', 0.33707865168539325), ('F1-Score', 0.49586776859504134), ('Specificity_(TNR)', 0.9938650306748467), ('ROC-AUC', 0.874543323912594), ('PR-AUC', 0.7271284566783014), ('LogLoss', 0.35627096542118075), ('MCC', 0.509194286731754)]), 'Validation': OrderedDict([('Accuracy', 0.8), ('Precision', 0.75), ('Recall_(Sensitivity/TPR)', 0.13043478260869565), ('F1-Score', 0.2222222222222222), ('Specificity_(TNR)', 0.9878048780487805), ('ROC-AUC', 0.8085896076352068), ('PR-AUC', 0.548320021533651), ('LogLoss', 0.432463694060989), ('MCC', 0.2554720166740535)]), 'Test': OrderedDict([('Accuracy', 0.7894736842105263), ('Precision', 0.8571428571428571), ('Recall_(Sensitivity/TPR)', 0.18181818181818182), ('F1-Score', 0.3), ('Specificity_(TNR)', 0.99), ('ROC-AUC', 0.7693939393939394), ('PR-AUC', 0.5859232921106323), ('LogLoss', 0.478200485483861), ('MCC', 0.3323470256441984)])}\n20:09:19 | INFO | AutoGluon evaluate() by split: {'Train': {'roc_auc': 0.8745433239125939}, 'Validation': {'roc_auc': 0.8085896076352068}, 'Test': {'roc_auc': 0.7693939393939393}}\n20:09:19 | INFO | Wrote full JSON â†’ /jetstream2/scratch/main/jobs/74504199/outputs/dataset_2d183589-25c2-4790-b2fa-caa57ab4ec3c.dat\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\nğŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n20:11:41 | INFO | Wrote HTML report â†’ /jetstream2/scratch/main/jobs/74504199/outputs/dataset_76884e07-6717-41c8-a70a-ff0b91598771.dat\n20:11:41 | INFO | Wrote predictor path â†’ predictor_path.txt\n20:11:41 | INFO | Wrote AutoGluon config â†’ /jetstream2/scratch/main/jobs/74504199/outputs/dataset_f5863c60-cfc2-4b85-8214-064db1705fbc.dat\n20:11:41 | INFO | âœ“ Output JSON results: /jetstream2/scratch/main/jobs/74504199/outputs/dataset_2d183589-25c2-4790-b2fa-caa57ab4ec3c.dat (15,942 bytes)\n20:11:41 | INFO | âœ“ Output HTML report: /jetstream2/scratch/main/jobs/74504199/outputs/dataset_76884e07-6717-41c8-a70a-ff0b91598771.dat (156,875 bytes)\n20:11:41 | INFO | âœ“ Output AutoGluon config: /jetstream2/scratch/main/jobs/74504199/outputs/dataset_f5863c60-cfc2-4b85-8214-064db1705fbc.dat (4,113 bytes)\n","job_messages":[],"dependencies":[],"job_metrics":null}
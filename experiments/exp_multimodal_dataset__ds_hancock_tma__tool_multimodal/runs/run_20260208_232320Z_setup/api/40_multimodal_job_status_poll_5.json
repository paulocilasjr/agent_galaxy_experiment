{"model_class":"Job","id":"bbd44e69cb8906b538f7c3278b60f690","history_id":"bbd44e69cb8906b5ce223e9a81174ae0","tool_id":"toolshed.g2.bx.psu.edu/repos/goeckslab/multimodal_learner/multimodal_learner/0.1.5","state":"error","exit_code":1,"create_time":"2026-02-09T14:34:05.816927","update_time":"2026-02-09T15:38:15.762794","galaxy_version":"25.1","external_id":null,"handler":null,"job_runner_name":null,"command_line":"set -e; ln -sf '/jetstream2/scratch/main/jobs/74500815/inputs/dataset_bed0da13-577a-4094-bb36-e678609c48ff.dat' 'train_input.csv'; ln -sf '/jetstream2/scratch/main/jobs/74500815/inputs/dataset_8afe987e-6cca-49ac-a972-45ab1376c13d.dat' 'test_input.csv';  export TORCH_HOME=\"./torch_cache\" && export HF_HOME=\"./hf_cache\" && export HUGGINGFACE_HUB_CACHE=\"./hf_cache/hub\" && mkdir -p \"./torch_cache\" \"./hf_cache/hub\" &&  python '/jetstream2/scratch/main/jobs/74500815/tool_files/multimodal_learner.py' --input_csv_train 'train_input.csv' --input_csv_test 'test_input.csv' --target_column '3' --sample_id_column '1'  --images_zip '/jetstream2/scratch/main/jobs/74500815/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat' --missing_image_strategy 'true' --backbone_image 'swin_base_patch4_window7_224.ms_in22k_ft_in1k'  --backbone_text 'microsoft/deberta-v3-base'  --preset 'medium_quality' --eval_metric 'roc_auc'  --random_seed '42' --time_limit 7200 --deterministic   --output_json '/jetstream2/scratch/main/jobs/74500815/outputs/dataset_56920be9-bdeb-4df0-abb0-c08c27a49bb9.dat' --output_html '/jetstream2/scratch/main/jobs/74500815/outputs/dataset_d77146d5-e8f3-444a-b30b-c212238941a4.dat' --output_config '/jetstream2/scratch/main/jobs/74500815/outputs/dataset_3b88e999-906e-45ff-88e7-8724c5732f83.dat'","user_email":null,"user_id":"92401dda9a0b9e33","command_version":"","params":{"target_column":"\"3\"","sample_id_selector":"{\"__current_case__\": 0, \"sample_id_column\": \"1\", \"use_sample_id\": \"yes\"}","test_dataset_conditional":"{\"__current_case__\": 0, \"has_test_dataset\": true, \"input_test\": {\"values\": [{\"id\": 168376039, \"src\": \"hda\"}]}}","backbone_text":"\"microsoft/deberta-v3-base\"","use_images_conditional":"{\"__current_case__\": 0, \"backbone_image\": \"swin_base_patch4_window7_224.ms_in22k_ft_in1k\", \"images_zip_repeat\": [{\"__index__\": 0, \"images_zip\": {\"values\": [{\"id\": 168376040, \"src\": \"hda\"}]}}], \"missing_image_strategy\": true, \"use_images\": true}","preset":"\"medium_quality\"","eval_metric":"\"roc_auc\"","random_seed":"\"42\"","time_limit":"\"7200\"","deterministic":"true","customize_defaults_conditional":"{\"__current_case__\": 1, \"customize_defaults\": false}","chromInfo":"\"/cvmfs/data.galaxyproject.org/managed/len/ucsc/?.len\"","dbkey":"\"?\"","__input_ext":"\"input\""},"inputs":{"input_csv":{"id":"f9cad7b01a472135214deb0f5acedc0b","src":"hda","uuid":"bed0da13-577a-4094-bb36-e678609c48ff"},"test_dataset_conditional|input_test":{"id":"f9cad7b01a4721356b6decc42b7e78f0","src":"hda","uuid":"8afe987e-6cca-49ac-a972-45ab1376c13d"},"use_images_conditional|images_zip_repeat_0|images_zip":{"id":"f9cad7b01a4721357c0e9f7ba4c68487","src":"hda","uuid":"666b7df2-0818-43d9-b778-cb5a83c8cdcd"}},"outputs":{"output_html":{"id":"f9cad7b01a47213546171c21fba899da","src":"hda","uuid":"d77146d5-e8f3-444a-b30b-c212238941a4"},"output_config":{"id":"f9cad7b01a4721356b71632e40b6d137","src":"hda","uuid":"3b88e999-906e-45ff-88e7-8724c5732f83"},"output_json":{"id":"f9cad7b01a472135b851449cf8da2447","src":"hda","uuid":"56920be9-bdeb-4df0-abb0-c08c27a49bb9"}},"copied_from_job_id":null,"output_collections":{},"tool_stdout":"","tool_stderr":"15:31:34 | INFO | === AutoGluon Training Wrapper Started ===\n15:31:34 | INFO | Working directory: /jetstream2/scratch/main/jobs/74500815/working\n15:31:34 | INFO | Command line: /jetstream2/scratch/main/jobs/74500815/tool_files/multimodal_learner.py --input_csv_train train_input.csv --input_csv_test test_input.csv --target_column 3 --sample_id_column 1 --images_zip /jetstream2/scratch/main/jobs/74500815/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat --missing_image_strategy true --backbone_image swin_base_patch4_window7_224.ms_in22k_ft_in1k --backbone_text microsoft/deberta-v3-base --preset medium_quality --eval_metric roc_auc --random_seed 42 --time_limit 7200 --deterministic --output_json /jetstream2/scratch/main/jobs/74500815/outputs/dataset_56920be9-bdeb-4df0-abb0-c08c27a49bb9.dat --output_html /jetstream2/scratch/main/jobs/74500815/outputs/dataset_d77146d5-e8f3-444a-b30b-c212238941a4.dat --output_config /jetstream2/scratch/main/jobs/74500815/outputs/dataset_3b88e999-906e-45ff-88e7-8724c5732f83.dat\n15:31:34 | INFO | Parsed args: {'train_dataset': 'train_input.csv', 'test_dataset': 'test_input.csv', 'target_column': '3', 'output_json': '/jetstream2/scratch/main/jobs/74500815/outputs/dataset_56920be9-bdeb-4df0-abb0-c08c27a49bb9.dat', 'output_html': '/jetstream2/scratch/main/jobs/74500815/outputs/dataset_d77146d5-e8f3-444a-b30b-c212238941a4.dat', 'output_config': '/jetstream2/scratch/main/jobs/74500815/outputs/dataset_3b88e999-906e-45ff-88e7-8724c5732f83.dat', 'images_zip': ['/jetstream2/scratch/main/jobs/74500815/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat'], 'missing_image_strategy': 'true', 'threshold': None, 'time_limit': 7200, 'deterministic': True, 'random_seed': 42, 'cross_validation': 'false', 'num_folds': 5, 'epochs': None, 'learning_rate': None, 'batch_size': None, 'num_workers': None, 'num_workers_eval': None, 'backbone_image': 'swin_base_patch4_window7_224.ms_in22k_ft_in1k', 'backbone_text': 'microsoft/deberta-v3-base', 'validation_size': 0.2, 'split_probabilities': [0.7, 0.1, 0.2], 'sample_id_column': '1', 'preset': 'medium_quality', 'eval_metric': 'roc_auc', 'hyperparameters': None}\n15:31:34 | INFO | Cache dirs: TORCH_HOME=./torch_cache HF_HOME=./hf_cache HUGGINGFACE_HUB_CACHE=./hf_cache/hub\n15:31:34 | INFO | Deterministic mode enabled (seed=42)\n15:31:34 | INFO | Train dataset loaded: 533 rows\n15:31:34 | INFO | Test dataset loaded: 134 rows\n15:31:34 | INFO | Target column '3' not found; using column #3 header 'target' instead.\n15:31:34 | INFO | Sample ID column '1' not found; using column #1 header 'patient_id' instead.\n15:31:34 | INFO | Extracting 1 image ZIP(s) to /jetstream2/scratch/main/jobs/74500815/tmp/autogluon_images_nsmaq1bd\n15:35:59 | INFO | Extracted dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat\n15:35:59 | INFO | Inferred image columns: ['CD3_image_path', 'CD8_image_path']\n15:36:16 | INFO | Dropped 13 rows with missing images → 520 remain\n15:36:17 | INFO | Dropped 1 rows with missing images → 133 remain\n15:36:17 | INFO | After cleanup → train: 520, test: 133\n15:36:17 | INFO | External test set → created val split (20%)\n15:36:17 | INFO | Final split distribution:\nsplit\ntrain    415\nval      105\nName: count, dtype: int64\n15:36:17 | INFO | Preprocessing complete — ready for AutoGluon training!\n15:36:17 | INFO | Final split counts:\nsplit\ntrain    415\nval      105\nName: count, dtype: int64\n15:36:17 | INFO | Using default training num_workers=8 (heuristic).\n15:36:17 | INFO | Using default inference num_workers=8 (heuristic).\n15:36:17 | INFO | AutoGluon config prepared: fit={'time_limit': 7200, 'seed': 42, 'presets': 'medium_quality'}, hyperparameters keys=['env', 'model', 'env.num_workers', 'env.num_workers_inference', 'model.timm_image.checkpoint_name', 'model.hf_text.checkpoint_name']\n15:36:17 | INFO | Fitting AutoGluon with 415 train / 105 val rows (internal test rows: 0, external test provided: True)\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20260209_153617\"\n=================== System Info ===================\nAutoGluon Version:  1.4.0\nPython Version:     3.10.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sat Jan 17 14:23:47 EST 2026\nCPU Count:          16\nPytorch Version:    2.7.1+cu126\nCUDA Version:       12.6\nGPU Count:          2\nMemory Avail:       56.39 GB / 58.59 GB (96.2%)\nDisk Space Avail:   27094.67 GB / 64000.00 GB (42.3%)\n===================================================\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [np.int64(0), np.int64(1)]\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n\nAutoMM starts to create your model. ✨✨✨\n\nTo track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /jetstream2/scratch/main/jobs/74500815/working/AutogluonModels/ag-20260209_153617\n    ```\n\nSeed set to 42\n/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n15:36:23 | INFO | Loading pretrained weights from Hugging Face hub (timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k)\n15:36:25 | INFO | [timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n15:36:25 | INFO | Missing keys (head.fc.weight, head.fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\nGPU Count: 2\nGPU Count to be Used: 2\nGPU 0 Name: GRID A100X-20C\nGPU 0 Memory: 1.65GB/20.0GB (Used/Total)\nGPU 1 Name: GRID A100X-20C\nGPU 1 Memory: 1.64GB/20.0GB (Used/Total)\n\nUsing 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nYou are using a CUDA device ('GRID A100X-20C') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\nInitializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\nYou are using a CUDA device ('GRID A100X-20C') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\nInitializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n[W209 15:36:48.529149465 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\nW0209 15:36:50.542000 18 torch/multiprocessing/spawn.py:169] Terminating process 159 via signal SIGTERM\nTraceback (most recent call last):\n  File \"/jetstream2/scratch/main/jobs/74500815/tool_files/multimodal_learner.py\", line 473, in <module>\n    main()\n  File \"/jetstream2/scratch/main/jobs/74500815/tool_files/multimodal_learner.py\", line 419, in main\n    predictor, data_ctx = run_autogluon_experiment(\n  File \"/jetstream2/scratch/main/jobs/74500815/tool_files/training_pipeline.py\", line 635, in run_autogluon_experiment\n    predictor.fit(**fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/autogluon/multimodal/predictor.py\", line 540, in fit\n    self._learner.fit(\n  File \"/usr/local/lib/python3.10/dist-packages/autogluon/multimodal/learners/base.py\", line 665, in fit\n    fit_returns = self.execute_fit()\n  File \"/usr/local/lib/python3.10/dist-packages/autogluon/multimodal/learners/base.py\", line 577, in execute_fit\n    attributes = self.fit_per_run(**self._fit_args)\n  File \"/usr/local/lib/python3.10/dist-packages/autogluon/multimodal/learners/base.py\", line 1358, in fit_per_run\n    self.run_trainer(\n  File \"/usr/local/lib/python3.10/dist-packages/autogluon/multimodal/learners/base.py\", line 1211, in run_trainer\n    trainer.fit(\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 584, in fit\n    call._call_and_handle_interrupt(\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 48, in _call_and_handle_interrupt\n    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/multiprocessing.py\", line 144, in launch\n    while not process_context.join():\n  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 215, in join\n    raise ProcessRaisedException(msg, error_index, failed_process.pid)\ntorch.multiprocessing.spawn.ProcessRaisedException: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 90, in _wrap\n    fn(i, *args)\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 630, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1033, in _run\n    self.strategy.setup_environment()\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/ddp.py\", line 155, in setup_environment\n    self.setup_distributed()\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/ddp.py\", line 207, in setup_distributed\n    _init_dist_connection(self.cluster_environment, self._process_group_backend, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/distributed.py\", line 283, in _init_dist_connection\n    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py\", line 81, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py\", line 95, in wrapper\n    func_return = func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 1717, in init_process_group\n    default_pg, _ = _new_process_group_helper(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 2074, in _new_process_group_helper\n    eager_backend.eager_connect_single_device(device_id)\ntorch.distributed.DistBackendError: NCCL error in: /pytorch/torch/csrc/distributed/c10d/NCCLUtils.cpp:77, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.26.2\nncclUnhandledCudaError: Call to CUDA function failed.\nLast error:\nCuda failure 'operation not supported'\n\n","job_stdout":"","job_stderr":"","stdout":"","stderr":"15:31:34 | INFO | === AutoGluon Training Wrapper Started ===\n15:31:34 | INFO | Working directory: /jetstream2/scratch/main/jobs/74500815/working\n15:31:34 | INFO | Command line: /jetstream2/scratch/main/jobs/74500815/tool_files/multimodal_learner.py --input_csv_train train_input.csv --input_csv_test test_input.csv --target_column 3 --sample_id_column 1 --images_zip /jetstream2/scratch/main/jobs/74500815/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat --missing_image_strategy true --backbone_image swin_base_patch4_window7_224.ms_in22k_ft_in1k --backbone_text microsoft/deberta-v3-base --preset medium_quality --eval_metric roc_auc --random_seed 42 --time_limit 7200 --deterministic --output_json /jetstream2/scratch/main/jobs/74500815/outputs/dataset_56920be9-bdeb-4df0-abb0-c08c27a49bb9.dat --output_html /jetstream2/scratch/main/jobs/74500815/outputs/dataset_d77146d5-e8f3-444a-b30b-c212238941a4.dat --output_config /jetstream2/scratch/main/jobs/74500815/outputs/dataset_3b88e999-906e-45ff-88e7-8724c5732f83.dat\n15:31:34 | INFO | Parsed args: {'train_dataset': 'train_input.csv', 'test_dataset': 'test_input.csv', 'target_column': '3', 'output_json': '/jetstream2/scratch/main/jobs/74500815/outputs/dataset_56920be9-bdeb-4df0-abb0-c08c27a49bb9.dat', 'output_html': '/jetstream2/scratch/main/jobs/74500815/outputs/dataset_d77146d5-e8f3-444a-b30b-c212238941a4.dat', 'output_config': '/jetstream2/scratch/main/jobs/74500815/outputs/dataset_3b88e999-906e-45ff-88e7-8724c5732f83.dat', 'images_zip': ['/jetstream2/scratch/main/jobs/74500815/inputs/dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat'], 'missing_image_strategy': 'true', 'threshold': None, 'time_limit': 7200, 'deterministic': True, 'random_seed': 42, 'cross_validation': 'false', 'num_folds': 5, 'epochs': None, 'learning_rate': None, 'batch_size': None, 'num_workers': None, 'num_workers_eval': None, 'backbone_image': 'swin_base_patch4_window7_224.ms_in22k_ft_in1k', 'backbone_text': 'microsoft/deberta-v3-base', 'validation_size': 0.2, 'split_probabilities': [0.7, 0.1, 0.2], 'sample_id_column': '1', 'preset': 'medium_quality', 'eval_metric': 'roc_auc', 'hyperparameters': None}\n15:31:34 | INFO | Cache dirs: TORCH_HOME=./torch_cache HF_HOME=./hf_cache HUGGINGFACE_HUB_CACHE=./hf_cache/hub\n15:31:34 | INFO | Deterministic mode enabled (seed=42)\n15:31:34 | INFO | Train dataset loaded: 533 rows\n15:31:34 | INFO | Test dataset loaded: 134 rows\n15:31:34 | INFO | Target column '3' not found; using column #3 header 'target' instead.\n15:31:34 | INFO | Sample ID column '1' not found; using column #1 header 'patient_id' instead.\n15:31:34 | INFO | Extracting 1 image ZIP(s) to /jetstream2/scratch/main/jobs/74500815/tmp/autogluon_images_nsmaq1bd\n15:35:59 | INFO | Extracted dataset_666b7df2-0818-43d9-b778-cb5a83c8cdcd.dat\n15:35:59 | INFO | Inferred image columns: ['CD3_image_path', 'CD8_image_path']\n15:36:16 | INFO | Dropped 13 rows with missing images → 520 remain\n15:36:17 | INFO | Dropped 1 rows with missing images → 133 remain\n15:36:17 | INFO | After cleanup → train: 520, test: 133\n15:36:17 | INFO | External test set → created val split (20%)\n15:36:17 | INFO | Final split distribution:\nsplit\ntrain    415\nval      105\nName: count, dtype: int64\n15:36:17 | INFO | Preprocessing complete — ready for AutoGluon training!\n15:36:17 | INFO | Final split counts:\nsplit\ntrain    415\nval      105\nName: count, dtype: int64\n15:36:17 | INFO | Using default training num_workers=8 (heuristic).\n15:36:17 | INFO | Using default inference num_workers=8 (heuristic).\n15:36:17 | INFO | AutoGluon config prepared: fit={'time_limit': 7200, 'seed': 42, 'presets': 'medium_quality'}, hyperparameters keys=['env', 'model', 'env.num_workers', 'env.num_workers_inference', 'model.timm_image.checkpoint_name', 'model.hf_text.checkpoint_name']\n15:36:17 | INFO | Fitting AutoGluon with 415 train / 105 val rows (internal test rows: 0, external test provided: True)\nNo path specified. Models will be saved in: \"AutogluonModels/ag-20260209_153617\"\n=================== System Info ===================\nAutoGluon Version:  1.4.0\nPython Version:     3.10.12\nOperating System:   Linux\nPlatform Machine:   x86_64\nPlatform Version:   #1 SMP PREEMPT_DYNAMIC Sat Jan 17 14:23:47 EST 2026\nCPU Count:          16\nPytorch Version:    2.7.1+cu126\nCUDA Version:       12.6\nGPU Count:          2\nMemory Avail:       56.39 GB / 58.59 GB (96.2%)\nDisk Space Avail:   27094.67 GB / 64000.00 GB (42.3%)\n===================================================\nAutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n\t2 unique label values:  [np.int64(0), np.int64(1)]\n\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n\nAutoMM starts to create your model. ✨✨✨\n\nTo track the learning progress, you can open a terminal and launch Tensorboard:\n    ```shell\n    # Assume you have installed tensorboard\n    tensorboard --logdir /jetstream2/scratch/main/jobs/74500815/working/AutogluonModels/ag-20260209_153617\n    ```\n\nSeed set to 42\n/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n15:36:23 | INFO | Loading pretrained weights from Hugging Face hub (timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k)\n15:36:25 | INFO | [timm/swin_base_patch4_window7_224.ms_in22k_ft_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n15:36:25 | INFO | Missing keys (head.fc.weight, head.fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.\nGPU Count: 2\nGPU Count to be Used: 2\nGPU 0 Name: GRID A100X-20C\nGPU 0 Memory: 1.65GB/20.0GB (Used/Total)\nGPU 1 Name: GRID A100X-20C\nGPU 1 Memory: 1.64GB/20.0GB (Used/Total)\n\nUsing 16bit Automatic Mixed Precision (AMP)\nGPU available: True (cuda), used: True\nTPU available: False, using: 0 TPU cores\nYou are using a CUDA device ('GRID A100X-20C') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\nInitializing distributed: GLOBAL_RANK: 0, MEMBER: 1/2\nYou are using a CUDA device ('GRID A100X-20C') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\nInitializing distributed: GLOBAL_RANK: 1, MEMBER: 2/2\n[W209 15:36:48.529149465 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\nW0209 15:36:50.542000 18 torch/multiprocessing/spawn.py:169] Terminating process 159 via signal SIGTERM\nTraceback (most recent call last):\n  File \"/jetstream2/scratch/main/jobs/74500815/tool_files/multimodal_learner.py\", line 473, in <module>\n    main()\n  File \"/jetstream2/scratch/main/jobs/74500815/tool_files/multimodal_learner.py\", line 419, in main\n    predictor, data_ctx = run_autogluon_experiment(\n  File \"/jetstream2/scratch/main/jobs/74500815/tool_files/training_pipeline.py\", line 635, in run_autogluon_experiment\n    predictor.fit(**fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/autogluon/multimodal/predictor.py\", line 540, in fit\n    self._learner.fit(\n  File \"/usr/local/lib/python3.10/dist-packages/autogluon/multimodal/learners/base.py\", line 665, in fit\n    fit_returns = self.execute_fit()\n  File \"/usr/local/lib/python3.10/dist-packages/autogluon/multimodal/learners/base.py\", line 577, in execute_fit\n    attributes = self.fit_per_run(**self._fit_args)\n  File \"/usr/local/lib/python3.10/dist-packages/autogluon/multimodal/learners/base.py\", line 1358, in fit_per_run\n    self.run_trainer(\n  File \"/usr/local/lib/python3.10/dist-packages/autogluon/multimodal/learners/base.py\", line 1211, in run_trainer\n    trainer.fit(\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 584, in fit\n    call._call_and_handle_interrupt(\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/call.py\", line 48, in _call_and_handle_interrupt\n    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/multiprocessing.py\", line 144, in launch\n    while not process_context.join():\n  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 215, in join\n    raise ProcessRaisedException(msg, error_index, failed_process.pid)\ntorch.multiprocessing.spawn.ProcessRaisedException: \n\n-- Process 1 terminated with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 90, in _wrap\n    fn(i, *args)\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/launchers/multiprocessing.py\", line 173, in _wrapping_function\n    results = function(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 630, in _fit_impl\n    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/trainer.py\", line 1033, in _run\n    self.strategy.setup_environment()\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/ddp.py\", line 155, in setup_environment\n    self.setup_distributed()\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/strategies/ddp.py\", line 207, in setup_distributed\n    _init_dist_connection(self.cluster_environment, self._process_group_backend, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/lightning/fabric/utilities/distributed.py\", line 283, in _init_dist_connection\n    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py\", line 81, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/c10d_logger.py\", line 95, in wrapper\n    func_return = func(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 1717, in init_process_group\n    default_pg, _ = _new_process_group_helper(\n  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 2074, in _new_process_group_helper\n    eager_backend.eager_connect_single_device(device_id)\ntorch.distributed.DistBackendError: NCCL error in: /pytorch/torch/csrc/distributed/c10d/NCCLUtils.cpp:77, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.26.2\nncclUnhandledCudaError: Call to CUDA function failed.\nLast error:\nCuda failure 'operation not supported'\n\n","job_messages":[{"desc":"Fatal error: Exit code 1 (Tool failed — see Tool Standard Error)","code_desc":"Tool failed — see Tool Standard Error","error_level":3.0,"type":"exit_code","exit_code":1},{"desc":"Fatal error: Exit code 1 ()","code_desc":"","error_level":3.0,"type":"exit_code","exit_code":1}],"dependencies":[],"job_metrics":null}
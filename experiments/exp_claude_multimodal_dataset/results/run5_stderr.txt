05:54:20 | INFO | === AutoGluon Training Wrapper Started ===
05:54:20 | INFO | Working directory: /jetstream2/scratch/main/jobs/74581421/working
05:54:20 | INFO | Command line: /jetstream2/scratch/main/jobs/74581421/tool_files/multimodal_learner.py --input_csv_train train_input.csv --input_csv_test test_input.csv --target_column 3 --sample_id_column 1 --images_zip /jetstream2/scratch/main/jobs/74581421/inputs/dataset_aa1a0699-528f-4f0f-ba9a-23399632190b.dat --missing_image_strategy false --backbone_image caformer_b36.sail_in22k_ft_in1k_384 --backbone_text microsoft/deberta-v3-base --preset best_quality --eval_metric roc_auc --random_seed 42 --time_limit 7200 --deterministic --validation_size 0.15 --split_probabilities 0.85 0.1 0.05 --threshold 0.12 --output_json /jetstream2/scratch/main/jobs/74581421/outputs/dataset_f5d06a91-33dc-44fd-a723-c21e754a9820.dat --output_html /jetstream2/scratch/main/jobs/74581421/outputs/dataset_d243f9b1-1f80-485c-a496-3d1e4576e635.dat --output_config /jetstream2/scratch/main/jobs/74581421/outputs/dataset_a7c7213e-e218-4724-9681-4cc550cc01b8.dat
05:54:20 | INFO | Parsed args: {'train_dataset': 'train_input.csv', 'test_dataset': 'test_input.csv', 'target_column': '3', 'output_json': '/jetstream2/scratch/main/jobs/74581421/outputs/dataset_f5d06a91-33dc-44fd-a723-c21e754a9820.dat', 'output_html': '/jetstream2/scratch/main/jobs/74581421/outputs/dataset_d243f9b1-1f80-485c-a496-3d1e4576e635.dat', 'output_config': '/jetstream2/scratch/main/jobs/74581421/outputs/dataset_a7c7213e-e218-4724-9681-4cc550cc01b8.dat', 'images_zip': ['/jetstream2/scratch/main/jobs/74581421/inputs/dataset_aa1a0699-528f-4f0f-ba9a-23399632190b.dat'], 'missing_image_strategy': 'false', 'threshold': 0.12, 'time_limit': 7200, 'deterministic': True, 'random_seed': 42, 'cross_validation': 'false', 'num_folds': 5, 'epochs': None, 'learning_rate': None, 'batch_size': None, 'num_workers': None, 'num_workers_eval': None, 'backbone_image': 'caformer_b36.sail_in22k_ft_in1k_384', 'backbone_text': 'microsoft/deberta-v3-base', 'validation_size': 0.15, 'split_probabilities': [0.85, 0.1, 0.05], 'sample_id_column': '1', 'preset': 'best_quality', 'eval_metric': 'roc_auc', 'hyperparameters': None}
05:54:20 | INFO | Cache dirs: TORCH_HOME=./torch_cache HF_HOME=./hf_cache HUGGINGFACE_HUB_CACHE=./hf_cache/hub
05:54:20 | INFO | Deterministic mode enabled (seed=42)
05:54:20 | INFO | Train dataset loaded: 533 rows
05:54:20 | INFO | Test dataset loaded: 134 rows
05:54:20 | INFO | Target column '3' not found; using column #3 header 'target' instead.
05:54:20 | INFO | Sample ID column '1' not found; using column #1 header 'patient_id' instead.
05:54:20 | INFO | Extracting 1 image ZIP(s) to /jetstream2/scratch/main/jobs/74581421/tmp/autogluon_images_1_ymqhy8
05:58:42 | INFO | Extracted dataset_aa1a0699-528f-4f0f-ba9a-23399632190b.dat
05:58:42 | INFO | Inferred image columns: ['CD3_image_path', 'CD8_image_path']
05:58:59 | INFO | Placeholder image created: /jetstream2/scratch/main/jobs/74581421/tmp/ag_placeholder_h199u0j0/placeholder_bbf679ec5eb1492ba17adc718a572580.png
05:59:01 | INFO | Filled 13 missing images with placeholder
05:59:01 | INFO | Filled 1 missing images with placeholder
05:59:01 | INFO | After cleanup â†’ train: 533, test: 134
05:59:01 | INFO | External test set â†’ created val split (15%)
05:59:01 | INFO | Final split distribution:
split
train    452
val       81
Name: count, dtype: int64
05:59:01 | INFO | Preprocessing complete â€” ready for AutoGluon training!
05:59:01 | INFO | Final split counts:
split
train    452
val       81
Name: count, dtype: int64
05:59:01 | INFO | Applying custom decision threshold 0.1200 for binary evaluation.
05:59:01 | INFO | Using default training num_workers=8 (heuristic).
05:59:01 | INFO | Using default inference num_workers=8 (heuristic).
05:59:01 | INFO | AutoGluon config prepared: fit={'time_limit': 7200, 'seed': 42, 'presets': 'best_quality'}, hyperparameters keys=['env', 'model', 'env.num_workers', 'env.num_workers_inference', 'model.timm_image.checkpoint_name', 'model.hf_text.checkpoint_name']
05:59:01 | INFO | Fitting AutoGluon with 452 train / 81 val rows (internal test rows: 0, external test provided: True)
No path specified. Models will be saved in: "AutogluonModels/ag-20260212_055901"
=================== System Info ===================
AutoGluon Version:  1.4.0
Python Version:     3.10.12
Operating System:   Linux
Platform Machine:   x86_64
Platform Version:   #1 SMP PREEMPT_DYNAMIC Sat Jan 17 14:23:47 EST 2026
CPU Count:          16
Pytorch Version:    2.7.1+cu126
CUDA Version:       12.6
GPU Count:          1
Memory Avail:       56.42 GB / 58.59 GB (96.3%)
Disk Space Avail:   20116.32 GB / 64000.00 GB (31.4%)
===================================================
AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).
	2 unique label values:  [np.int64(0), np.int64(1)]
	If 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])

AutoMM starts to create your model. âœ¨âœ¨âœ¨

To track the learning progress, you can open a terminal and launch Tensorboard:
    ```shell
    # Assume you have installed tensorboard
    tensorboard --logdir /jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901
    ```

Seed set to 42
/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.
  warnings.warn(
05:59:11 | INFO | Loading pretrained weights from Hugging Face hub (timm/caformer_b36.sail_in22k_ft_in1k_384)
05:59:15 | INFO | [timm/caformer_b36.sail_in22k_ft_in1k_384] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
05:59:15 | INFO | Missing keys (head.fc.fc2.weight, head.fc.fc2.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
GPU Count: 1
GPU Count to be Used: 1
GPU 0 Name: GRID A100X-20C
GPU 0 Memory: 1.65GB/20.0GB (Used/Total)

Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/model_summary/model_summary.py:242: Precision 16-mixed is not supported by the model summary.  Estimated model size in MB will not be accurate. Using 32 bits instead.

  | Name              | Type                | Params | Mode  | FLOPs
--------------------------------------------------------------------------
0 | model             | MultimodalFusionMLP | 282 M  | train | 0    
1 | validation_metric | BinaryAUROC         | 0      | train | 0    
2 | loss_func         | CrossEntropyLoss    | 0      | train | 0    
--------------------------------------------------------------------------
282 M     Trainable params
0         Non-trainable params
282 M     Total params
1,128.085 Total estimated model params size (MB)
1183      Modules in train mode
0         Modules in eval mode
0         Total Flops
/usr/local/lib/python3.10/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score
  warnings.warn(*args, **kwargs)
Epoch 0, global step 1: 'val_roc_auc' reached 0.53226 (best 0.53226), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=0-step=1.ckpt' as top 3
Epoch 0, global step 4: 'val_roc_auc' reached 0.57258 (best 0.57258), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=0-step=4.ckpt' as top 3
Epoch 1, global step 5: 'val_roc_auc' reached 0.61715 (best 0.61715), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=1-step=5.ckpt' as top 3
Epoch 1, global step 8: 'val_roc_auc' was not in top 3
Epoch 2, global step 9: 'val_roc_auc' was not in top 3
Epoch 2, global step 12: 'val_roc_auc' reached 0.60526 (best 0.61715), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=2-step=12.ckpt' as top 3
Epoch 3, global step 13: 'val_roc_auc' reached 0.65407 (best 0.65407), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=3-step=13.ckpt' as top 3
Epoch 3, global step 16: 'val_roc_auc' reached 0.68718 (best 0.68718), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=3-step=16.ckpt' as top 3
Epoch 4, global step 17: 'val_roc_auc' reached 0.63413 (best 0.68718), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=4-step=17.ckpt' as top 3
Epoch 4, global step 20: 'val_roc_auc' was not in top 3
Epoch 5, global step 21: 'val_roc_auc' reached 0.67572 (best 0.68718), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=5-step=21.ckpt' as top 3
Epoch 5, global step 24: 'val_roc_auc' reached 0.68761 (best 0.68761), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=5-step=24.ckpt' as top 3
Epoch 6, global step 25: 'val_roc_auc' reached 0.67742 (best 0.68761), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=6-step=25.ckpt' as top 3
Epoch 6, global step 28: 'val_roc_auc' was not in top 3
Epoch 7, global step 29: 'val_roc_auc' was not in top 3
Epoch 7, global step 32: 'val_roc_auc' was not in top 3
Epoch 8, global step 33: 'val_roc_auc' was not in top 3
Epoch 8, global step 36: 'val_roc_auc' was not in top 3
Epoch 9, global step 37: 'val_roc_auc' reached 0.69610 (best 0.69610), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=9-step=37.ckpt' as top 3
Epoch 9, global step 40: 'val_roc_auc' reached 0.70289 (best 0.70289), saving model to '/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901/epoch=9-step=40.ckpt' as top 3
Epoch 10, global step 41: 'val_roc_auc' was not in top 3
Epoch 10, global step 44: 'val_roc_auc' was not in top 3
Epoch 11, global step 45: 'val_roc_auc' was not in top 3
Epoch 11, global step 48: 'val_roc_auc' was not in top 3
Epoch 12, global step 49: 'val_roc_auc' was not in top 3
Epoch 12, global step 52: 'val_roc_auc' was not in top 3
Epoch 13, global step 53: 'val_roc_auc' was not in top 3
Epoch 13, global step 56: 'val_roc_auc' was not in top 3
Epoch 14, global step 57: 'val_roc_auc' was not in top 3
Epoch 14, global step 60: 'val_roc_auc' was not in top 3
Start to fuse 3 checkpoints via the greedy soup algorithm.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
AutoMM has created your model. ðŸŽ‰ðŸŽ‰ðŸŽ‰

To load the model, use the code below:
    ```python
    from autogluon.multimodal import MultiModalPredictor
    predictor = MultiModalPredictor.load("/jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901")
    ```

If you are not satisfied with the model, try to increase the training time, 
adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),
or post issues on GitHub (https://github.com/autogluon/autogluon/issues).


06:33:49 | INFO | AutoGluon training finished. Model path: /jetstream2/scratch/main/jobs/74581421/working/AutogluonModels/ag-20260212_055901
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
06:37:23 | INFO | Here's the model summary:The model achieved score '0.6553480625152588' on the validation metric 'roc_auc'. The total training time is 0:34:47.688961
06:37:23 | INFO | Evaluation complete; splits: ['Train', 'Validation', 'Test']
06:37:23 | INFO | Transparent metrics by split: {'Train': OrderedDict([('Accuracy', 0.8805309734513275), ('Precision', 0.8928571428571429), ('Recall_(Sensitivity/TPR)', 0.5102040816326531), ('F1-Score', 0.6493506493506493), ('Specificity_(TNR)', 0.9830508474576272), ('ROC-AUC', 0.9086388792805258), ('PR-AUC', 0.8042869017837264), ('LogLoss', 0.2998322892520914), ('MCC', 0.616942226172259)]), 'Validation': OrderedDict([('Accuracy', 0.7654320987654321), ('Precision', 0.5), ('Recall_(Sensitivity/TPR)', 0.2631578947368421), ('F1-Score', 0.3448275862068966), ('Specificity_(TNR)', 0.9193548387096774), ('ROC-AUC', 0.7028862478777589), ('PR-AUC', 0.501838566170991), ('LogLoss', 0.5382191303229656), ('MCC', 0.23509134482124505)]), 'Test': OrderedDict([('Accuracy', 0.6791044776119403), ('Precision', 0.421875), ('Recall_(Sensitivity/TPR)', 0.8181818181818182), ('F1-Score', 0.5567010309278351), ('Specificity_(TNR)', 0.6336633663366337), ('ROC-AUC', 0.8052805280528053), ('PR-AUC', 0.5719304650171457), ('LogLoss', 0.46277279493218587), ('MCC', 0.38973401182637774)])}
06:37:23 | INFO | AutoGluon evaluate() by split: {'Train': {'roc_auc': 0.9086388792805257}, 'Validation': {'roc_auc': 0.702886247877759}, 'Test': {'roc_auc': 0.8052805280528053}}
06:37:23 | INFO | Wrote full JSON â†’ /jetstream2/scratch/main/jobs/74581421/outputs/dataset_f5d06a91-33dc-44fd-a723-c21e754a9820.dat
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
06:39:55 | INFO | Wrote HTML report â†’ /jetstream2/scratch/main/jobs/74581421/outputs/dataset_d243f9b1-1f80-485c-a496-3d1e4576e635.dat
06:39:55 | INFO | Wrote predictor path â†’ predictor_path.txt
06:39:55 | INFO | Wrote AutoGluon config â†’ /jetstream2/scratch/main/jobs/74581421/outputs/dataset_a7c7213e-e218-4724-9681-4cc550cc01b8.dat
06:39:55 | INFO | âœ“ Output JSON results: /jetstream2/scratch/main/jobs/74581421/outputs/dataset_f5d06a91-33dc-44fd-a723-c21e754a9820.dat (18,146 bytes)
06:39:55 | INFO | âœ“ Output HTML report: /jetstream2/scratch/main/jobs/74581421/outputs/dataset_d243f9b1-1f80-485c-a496-3d1e4576e635.dat (158,879 bytes)
06:39:55 | INFO | âœ“ Output AutoGluon config: /jetstream2/scratch/main/jobs/74581421/outputs/dataset_a7c7213e-e218-4724-9681-4cc550cc01b8.dat (4,117 bytes)
